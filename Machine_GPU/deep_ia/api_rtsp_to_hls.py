# # api2_rtsp_to_hls.py
# import cv2
# import numpy as np
# import subprocess
# import threading
# import time
# import os
# import shutil
# from fastapi import FastAPI, Query, HTTPException
# from fastapi.responses import JSONResponse, StreamingResponse, FileResponse
# from ultralytics import YOLO
# import asyncio
# import re
# import uuid
# import logging
# from fastapi.middleware.cors import CORSMiddleware

# # Configuration des logs
# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
# logger = logging.getLogger(__name__)

# app = FastAPI(title="RTSP to HLS with AI Detection")

# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )

# # Mod√®les YOLO
# model_general = YOLO("yolov8n.pt")
# model_face = YOLO("yolov8n-face.pt")

# # Configuration
# ALLOWED_CLASSES = ["person", "phone"]
# HTTP_PORT = 8020
# RTSP_SERVER_IP = "192.168.1.153"
# HLS_OUTPUT_DIR = "tmp/hls_output"
# HLS_SEGMENT_TIME = 4
# HLS_LIST_SIZE = 10

# # Variables globales
# active_processes = {}  # {stream_id: {process, frame, lock, etc.}}
# processing_enabled = {}  # {stream_id: True/False}

# # Cr√©ation des r√©pertoires n√©cessaires
# os.makedirs(HLS_OUTPUT_DIR, exist_ok=True)
# for stream_id in ["youtube", "youtubelive", "detection"]:
#     os.makedirs(f"{HLS_OUTPUT_DIR}/{stream_id}", exist_ok=True)

# def cleanup_hls_output(stream_id):
#     """Nettoie le r√©pertoire HLS de sortie pour un flux sp√©cifique."""
#     output_dir = f"{HLS_OUTPUT_DIR}/{stream_id}"
#     if os.path.exists(output_dir):
#         for file in os.listdir(output_dir):
#             file_path = os.path.join(output_dir, file)
#             try:
#                 if os.path.isfile(file_path):
#                     os.unlink(file_path)
#             except Exception as e:
#                 logger.error(f"‚ùå Erreur suppression {file_path}: {str(e)}")

# def detect_objects(frame, detect_list):
#     """Applique les d√©tections IA sur une frame."""
    
#     # D√©tection objets
#     if any(t in detect_list for t in ["person", "phone", "all"]):
#         results = model_general(frame, conf=0.4)[0]
#         for box in results.boxes:
#             cls_id = int(box.cls[0].item())
#             label = model_general.model.names[cls_id].lower()
#             conf = float(box.conf[0].item())

#             if ("all" in detect_list and label in ALLOWED_CLASSES) or (label in detect_list):
#                 x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
#                 cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
#                 cv2.putText(frame, f"{label} {conf:.2f}", (x1, y1 - 10),
#                             cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    
#     # D√©tection visages
#     if "face" in detect_list or "all" in detect_list:
#         results = model_face(frame, conf=0.5)[0]
#         for box in results.boxes:
#             x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
#             cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 2)
#             cv2.putText(frame, "Face", (x1, y1 - 10),
#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)
    
#     return frame

# def start_hls_process(stream_id, quality="hd"):
#     """D√©marre le processus FFmpeg HLS pour un flux."""
#     # Nettoyer le r√©pertoire HLS
#     cleanup_hls_output(stream_id)
    
#     # Pr√©parer les dossiers
#     output_dir = f"{HLS_OUTPUT_DIR}/{stream_id}"
#     os.makedirs(output_dir, exist_ok=True)
    
#     # Param√®tres de r√©solution
#     resolution = "1280x720" if quality == "hd" else "854x480"
    
#     cmd = [
#         'ffmpeg',
#         '-y',
#         '-f', 'rawvideo',
#         '-pix_fmt', 'bgr24',
#         '-s', resolution,
#         '-r', '25',
#         '-i', '-',
#         '-c:v', 'libx264',
#         '-preset', 'ultrafast',
#         '-tune', 'zerolatency',
#         '-f', 'hls',
#         '-hls_time', str(HLS_SEGMENT_TIME),
#         '-hls_list_size', str(HLS_LIST_SIZE),
#         '-hls_flags', 'delete_segments+append_list',
#         '-hls_segment_filename', f'{output_dir}/segment_%03d.ts',
#         f'{output_dir}/stream.m3u8'
#     ]
    
#     process = subprocess.Popen(
#         cmd,
#         stdin=subprocess.PIPE,
#         stdout=subprocess.PIPE,
#         stderr=subprocess.PIPE,
#         bufsize=10**8,
#         universal_newlines=False
#     )
    
#     logger.info(f"‚úÖ Processus HLS d√©marr√© pour {stream_id}")
#     return process

# def process_rtsp_stream(stream_id, rtsp_url, detect_list=None, quality="hd"):
#     """Traite un flux RTSP pour la d√©tection IA et la conversion HLS."""
#     if detect_list is None:
#         detect_list = ["all"]
    
#     # Cr√©er un verrou
#     frame_lock = threading.Lock()
#     current_frame = None
    
#     # D√©marrer le processus HLS
#     hls_process = start_hls_process(stream_id, quality)
    
#     # Stockage global
#     active_processes[stream_id] = {
#         'frame_lock': frame_lock,
#         'current_frame': current_frame,
#         'hls_process': hls_process,
#         'detect_list': detect_list,
#         'quality': quality,
#         'rtsp_url': rtsp_url,
#         'segments_generated': 0,
#         'last_segment_time': time.time()
#     }
    
#     # Activer le traitement
#     processing_enabled[stream_id] = True
    
#     def processing_thread():
#         nonlocal current_frame
        
#         retry_count = 0
#         max_retries = 5
        
#         while processing_enabled.get(stream_id, False):
#             try:
#                 # Ouvrir le flux RTSP
#                 cap = cv2.VideoCapture(rtsp_url)
#                 if not cap.isOpened():
#                     logger.error(f"‚ùå Impossible d'ouvrir le flux RTSP: {rtsp_url}")
#                     retry_count += 1
                    
#                     if retry_count >= max_retries:
#                         logger.error(f"‚ùå Abandon apr√®s {max_retries} tentatives: {stream_id}")
#                         processing_enabled[stream_id] = False
#                         break
                        
#                     time.sleep(2)
#                     continue
                
#                 logger.info(f"‚úÖ Flux RTSP ouvert: {rtsp_url}")
#                 retry_count = 0  # R√©initialiser le compteur de tentatives
#                 frame_count = 0
                
#                 # Param√®tres de r√©solution
#                 target_width = 1280 if quality == "hd" else 854
#                 target_height = 720 if quality == "hd" else 480
                
#                 while processing_enabled.get(stream_id, False):
#                     ret, frame = cap.read()
#                     if not ret:
#                         logger.warning(f"‚ö†Ô∏è Erreur lecture frame: {stream_id}")
#                         break
                    
#                     frame_count += 1
                    
#                     # Appliquer la d√©tection IA
#                     processed_frame = detect_objects(frame, detect_list)
                    
#                     # Redimensionner si n√©cessaire
#                     height, width = processed_frame.shape[:2]
#                     if width != target_width or height != target_height:
#                         processed_frame = cv2.resize(processed_frame, (target_width, target_height))
                    
#                     # Mettre √† jour le frame pour la visualisation HTTP
#                     with frame_lock:
#                         current_frame = processed_frame.copy()
#                         active_processes[stream_id]['current_frame'] = current_frame
                    
#                     # Envoyer √† FFmpeg pour HLS
#                     try:
#                         if stream_id in active_processes and active_processes[stream_id]['hls_process']:
#                             active_processes[stream_id]['hls_process'].stdin.write(processed_frame.tobytes())
#                             active_processes[stream_id]['hls_process'].stdin.flush()
#                     except BrokenPipeError:
#                         logger.error(f"‚ö†Ô∏è Pipe cass√©, red√©marrage HLS: {stream_id}")
#                         if stream_id in active_processes:
#                             # Red√©marrer le processus HLS
#                             if active_processes[stream_id]['hls_process']:
#                                 try:
#                                     active_processes[stream_id]['hls_process'].terminate()
#                                 except:
#                                     pass
#                             active_processes[stream_id]['hls_process'] = start_hls_process(stream_id, quality)
#                         break
                    
#                     # Log p√©riodique
#                     if frame_count % 100 == 0:
#                         logger.info(f"üìä {stream_id}: {frame_count} frames trait√©es")
                        
#                         # Mettre √† jour le compteur de segments
#                         active_processes[stream_id]['segments_generated'] += 1
#                         active_processes[stream_id]['last_segment_time'] = time.time()
                
#                 cap.release()
                
#                 # Si le traitement est toujours actif, attendre avant de r√©essayer
#                 if processing_enabled.get(stream_id, False):
#                     time.sleep(2)
                
#             except Exception as e:
#                 logger.error(f"‚ùå Erreur traitement {stream_id}: {str(e)}")
#                 time.sleep(2)
        
#         # Nettoyage
#         if stream_id in active_processes:
#             if active_processes[stream_id]['hls_process']:
#                 try:
#                     active_processes[stream_id]['hls_process'].terminate()
#                 except:
#                     pass
#             del active_processes[stream_id]
        
#         logger.info(f"üõë Traitement termin√©: {stream_id}")
    
#     # D√©marrer le thread de traitement
#     threading.Thread(target=processing_thread, daemon=True).start()
    
#     return {
#         'stream_id': stream_id,
#         'rtsp_url': rtsp_url,
#         'hls_url': f"http://{RTSP_SERVER_IP}:{HTTP_PORT}/hls/{stream_id}/stream.m3u8",
#         'mjpeg_url': f"http://{RTSP_SERVER_IP}:{HTTP_PORT}/stream/{stream_id}.mjpg",
#         'detect_list': detect_list,
#         'quality': quality
#     }

# def stop_rtsp_processing(stream_id):
#     """Arr√™te le traitement d'un flux RTSP."""
#     if stream_id not in processing_enabled:
#         return False, "Flux non trouv√©"
    
#     processing_enabled[stream_id] = False
    
#     if stream_id in active_processes:
#         process = active_processes[stream_id].get('hls_process')
#         if process:
#             try:
#                 process.stdin.close()
#                 process.terminate()
#                 process.wait(timeout=5)
#             except:
#                 pass
    
#     logger.info(f"üõë Traitement arr√™t√©: {stream_id}")
#     return True, "Traitement arr√™t√©"

# @app.get("/api/start")
# async def start_processing(
#     rtsp_url: str = Query(..., description="URL RTSP √† traiter"),
#     stream_id: str = Query(..., description="Identifiant du flux de sortie"),
#     detect: str = Query("all", description="Objets √† d√©tecter (person,face,phone,all)"),
#     q: str = Query("hd", description="Qualit√©: hd ou low")
# ):
#     """D√©marre le traitement d'un flux RTSP avec d√©tection IA et conversion HLS."""
#     # Valider les param√®tres
#     valid_targets = {"person", "face", "phone", "all"}
#     detect_list = [d.strip().lower() for d in detect.split(",") if d.strip().lower() in valid_targets]
#     if not detect_list:
#         detect_list = ["all"]
    
#     quality = q if q in ["hd", "low"] else "hd"
    
#     # V√©rifier si le traitement est d√©j√† en cours
#     if stream_id in processing_enabled and processing_enabled[stream_id]:
#         return JSONResponse({
#             "status": "Traitement d√©j√† en cours",
#             "stream_id": stream_id,
#             "hls_url": f"http://{RTSP_SERVER_IP}:{HTTP_PORT}/hls/{stream_id}/stream.m3u8"
#         })
    
#     # D√©marrer le traitement
#     result = process_rtsp_stream(stream_id, rtsp_url, detect_list, quality)
    
#     return JSONResponse({
#         "status": "Traitement d√©marr√©",
#         **result
#     })

# @app.get("/api/stop")
# async def stop_processing(
#     stream_id: str = Query(..., description="Identifiant du flux √† arr√™ter")
# ):
#     """Arr√™te le traitement d'un flux."""
#     success, message = stop_rtsp_processing(stream_id)
    
#     if success:
#         return JSONResponse({
#             "status": "success",
#             "message": message
#         })
#     else:
#         raise HTTPException(
#             status_code=404,
#             detail=message
#         )

# @app.get("/api/status")
# async def get_status():
#     """R√©cup√®re l'√©tat de tous les flux actifs."""
#     streams_status = {}
    
#     for stream_id, enabled in processing_enabled.items():
#         if enabled and stream_id in active_processes:
#             info = active_processes[stream_id]
#             streams_status[stream_id] = {
#                 "active": True,
#                 "rtsp_url": info.get('rtsp_url'),
#                 "segments_generated": info.get('segments_generated', 0),
#                 "last_segment_time": info.get('last_segment_time', 0),
#                 "hls_url": f"http://{RTSP_SERVER_IP}:{HTTP_PORT}/hls/{stream_id}/stream.m3u8",
#                 "mjpeg_url": f"http://{RTSP_SERVER_IP}:{HTTP_PORT}/stream/{stream_id}.mjpg",
#                 "detect_list": info.get('detect_list', []),
#                 "quality": info.get('quality', 'hd')
#             }
    
#     return JSONResponse({
#         "active_streams": streams_status,
#         "count": len(streams_status)
#     })

# @app.get("/api/status/{stream_id}")
# async def get_stream_status(stream_id: str):
#     """R√©cup√®re l'√©tat d'un flux sp√©cifique."""
#     if stream_id not in processing_enabled or not processing_enabled[stream_id]:
#         raise HTTPException(
#             status_code=404,
#             detail="Flux non trouv√© ou inactif"
#         )
    
#     if stream_id not in active_processes:
#         raise HTTPException(
#             status_code=404,
#             detail="Informations de flux non disponibles"
#         )
    
#     info = active_processes[stream_id]
#     return JSONResponse({
#         "stream_id": stream_id,
#         "active": processing_enabled[stream_id],
#         "rtsp_url": info.get('rtsp_url'),
#         "segments_generated": info.get('segments_generated', 0),
#         "last_segment_time": info.get('last_segment_time', 0),
#         "hls_url": f"http://{RTSP_SERVER_IP}:{HTTP_PORT}/hls/{stream_id}/stream.m3u8",
#         "mjpeg_url": f"http://{RTSP_SERVER_IP}:{HTTP_PORT}/stream/{stream_id}.mjpg",
#         "detect_list": info.get('detect_list', []),
#         "quality": info.get('quality', 'hd')
#     })

# @app.get("/stream/{stream_id}.mjpg")
# async def video_feed(stream_id: str):
#     """Flux vid√©o HTTP MJPEG pour un flux sp√©cifique."""
#     if stream_id not in active_processes:
#         raise HTTPException(
#             status_code=404,
#             detail="Flux non trouv√©"
#         )
    
#     async def generate():
#         while stream_id in active_processes and processing_enabled.get(stream_id, False):
#             with active_processes[stream_id]['frame_lock']:
#                 if active_processes[stream_id]['current_frame'] is None:
#                     await asyncio.sleep(0.1)
#                     continue
                
#                 _, buffer = cv2.imencode('.jpg', active_processes[stream_id]['current_frame'], [
#                     int(cv2.IMWRITE_JPEG_QUALITY), 70
#                 ])
#                 frame_data = buffer.tobytes()

#             yield (
#                 b"--frame\r\n"
#                 b"Content-Type: image/jpeg\r\n\r\n" + frame_data + b"\r\n"
#             )
#             await asyncio.sleep(0.03)

#     return StreamingResponse(
#         generate(),
#         media_type="multipart/x-mixed-replace; boundary=frame"
#     )

# @app.get("/hls/{stream_id}/{file_path:path}")
# async def serve_hls(stream_id: str, file_path: str):
#     """Sert les fichiers HLS pour un flux sp√©cifique."""
#     file_location = f"{HLS_OUTPUT_DIR}/{stream_id}/{file_path}"
#     if not os.path.exists(file_location):
#         raise HTTPException(status_code=404)
    
#     return FileResponse(
#         file_location,
#         headers={
#             "Access-Control-Allow-Origin": "*",
#             "Cache-Control": "no-cache"
#         }
#     )

# @app.get("/")
# def accueil():
#     return {
#         "message": "API RTSP vers HLS avec d√©tection IA",
#         "version": "1.0.0",
#         "endpoints": {
#             "start": "/api/start?rtsp_url=rtsp://...&stream_id=...",
#             "stop": "/api/stop?stream_id=...",
#             "status": "/api/status",
#             "stream": "/stream/{stream_id}.mjpg",
#             "hls": "/hls/{stream_id}/stream.m3u8"
#         }
#     }

# if __name__ == '__main__':
#     import uvicorn
    
#     # Nettoyer les r√©pertoires de sortie au d√©marrage
#     for stream_id in ["youtube", "youtubelive", "detection"]:
#         cleanup_hls_output(stream_id)
    
#     uvicorn.run(app, host="0.0.0.0", port=HTTP_PORT)






####################`TEST`######################

# api_rtsp_to_hls.py

# import os
# import subprocess
# import threading
# import time
# import cv2
# import numpy as np
# import logging
# from pathlib import Path
# from fastapi import FastAPI, Query, HTTPException
# from fastapi.responses import JSONResponse, FileResponse
# from fastapi.staticfiles import StaticFiles
# from ultralytics import YOLO
# import shutil

# # Configuration du logging
# logging.basicConfig(level=logging.INFO)
# logger = logging.getLogger(__name__)

# app = FastAPI(title="RTSP to HLS Converter with AI Detection")

# # Configuration
# HLS_OUTPUT_DIR = "tmp/hls_output"
# HLS_ANALYTICS_DIR = f"{HLS_OUTPUT_DIR}/analytics"
# HTTP_PORT = 8020

# # S'assurer que les r√©pertoires existent
# Path(HLS_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
# Path(HLS_ANALYTICS_DIR).mkdir(parents=True, exist_ok=True)

# # Charger les mod√®les YOLO une seule fois au d√©marrage
# try:
#     yolo_model = YOLO("yolov8n.pt")  # Mod√®le g√©n√©ral pour la d√©tection d'objets
#     face_model = YOLO("yolov8n-face.pt")  # Mod√®le sp√©cifique pour la d√©tection de visages
#     logger.info("Mod√®les YOLO charg√©s avec succ√®s")
# except Exception as e:
#     logger.error(f"Erreur lors du chargement des mod√®les YOLO: {str(e)}")
#     yolo_model = None
#     face_model = None

# # Variables globales
# current_process = None
# ai_process = None
# process_lock = threading.Lock()
# restart_event = threading.Event()
# active_rtsp_url = None
# ai_enabled = True
# detection_results = {
#     "objects": {},
#     "faces": 0,
#     "last_update": None
# }

# def draw_boxes(frame, results, is_face=False):
#     """Dessine les bo√Ætes de d√©tection sur l'image"""
#     annotated_frame = frame.copy()
    
#     if results.boxes:
#         for box in results.boxes:
#             # R√©cup√©rer les coordonn√©es et la classe
#             x1, y1, x2, y2 = map(int, box.xyxy[0])
#             conf = float(box.conf[0])
            
#             if is_face:
#                 # Rouge pour les visages
#                 color = (0, 0, 255)
#                 label = f"Face: {conf:.2f}"
#             else:
#                 # Vert pour les objets
#                 color = (0, 255, 0)
#                 cls = int(box.cls[0])
#                 class_name = results.names[cls]
#                 label = f"{class_name}: {conf:.2f}"
            
#             # Dessiner la bo√Æte
#             cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
            
#             # Ajouter le texte
#             cv2.putText(
#                 annotated_frame, 
#                 label, 
#                 (x1, y1 - 10), 
#                 cv2.FONT_HERSHEY_SIMPLEX, 
#                 0.5, 
#                 color, 
#                 2
#             )
    
#     return annotated_frame

# def ai_detection_thread(rtsp_url):
#     """Thread qui effectue la d√©tection d'objets et de visages"""
#     global detection_results
    
#     logger.info(f"D√©marrage du thread de d√©tection AI pour: {rtsp_url}")
    
#     try:
#         # Ouvrir le flux RTSP
#         cap = cv2.VideoCapture(rtsp_url)
#         if not cap.isOpened():
#             logger.error(f"Impossible d'ouvrir le flux RTSP: {rtsp_url}")
#             return
            
#         frame_count = 0
        
#         while not restart_event.is_set() and cap.isOpened():
#             # Lire une frame
#             ret, frame = cap.read()
#             if not ret:
#                 logger.warning("√âchec de lecture du flux RTSP")
#                 time.sleep(1)
#                 continue
                
#             # Traiter une frame sur 5 pour all√©ger le processus
#             frame_count += 1
#             if frame_count % 5 != 0:
#                 continue
                
#             # D√©tection avec YOLOv8
#             if yolo_model:
#                 try:
#                     # D√©tection d'objets
#                     results = yolo_model(frame, conf=0.25)
                    
#                     # Comptage des objets par classe
#                     objects_detected = {}
#                     if results and results[0].boxes:
#                         for box in results[0].boxes:
#                             cls = int(box.cls[0])
#                             class_name = results[0].names[cls]
#                             if class_name in objects_detected:
#                                 objects_detected[class_name] += 1
#                             else:
#                                 objects_detected[class_name] = 1
                    
#                     # D√©tection de visages
#                     face_results = face_model(frame, conf=0.25)
#                     face_count = len(face_results[0].boxes) if face_results and face_results[0].boxes else 0
                    
#                     # Mettre √† jour les r√©sultats de d√©tection
#                     detection_results = {
#                         "objects": objects_detected,
#                         "faces": face_count,
#                         "last_update": time.strftime("%H:%M:%S")
#                     }
                    
#                     # Cr√©er et sauvegarder une image annot√©e
#                     annotated_frame = draw_boxes(frame, results[0])
#                     # Ajouter les annotations de visages
#                     annotated_frame = draw_boxes(annotated_frame, face_results[0], is_face=True)
                    
#                     # Enregistrer l'image annot√©e
#                     cv2.imwrite(f"{HLS_ANALYTICS_DIR}/latest_detection.jpg", annotated_frame)
                    
#                 except Exception as e:
#                     logger.error(f"Erreur lors de la d√©tection: {str(e)}")
            
#             time.sleep(0.2)  # Pour √©viter une utilisation trop intensive du CPU
            
#         cap.release()
#         logger.info("Thread de d√©tection AI termin√©")
        
#     except Exception as e:
#         logger.error(f"Erreur dans le thread de d√©tection AI: {str(e)}")

# def start_hls_conversion(rtsp_url):
#     """D√©marre la conversion RTSP vers HLS"""
#     global current_process, active_rtsp_url
    
#     # Nettoyer les anciens fichiers .ts et .m3u8
#     for file in os.listdir(HLS_OUTPUT_DIR):
#         file_path = os.path.join(HLS_OUTPUT_DIR, file)
#         if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
#             os.remove(file_path)
    
#     # Commande FFmpeg pour convertir RTSP en HLS avec conservation de tous les segments
#     ffmpeg_cmd = [
#         "ffmpeg",
#         "-hide_banner",
#         "-loglevel", "error",
#         "-fflags", "+genpts",
#         "-rtsp_transport", "tcp",
#         "-i", rtsp_url,
#         "-c:v", "copy",               # Copy video codec
#         "-c:a", "aac",                # Convert audio to AAC
#         "-hls_time", "2",             # Segment duration in seconds
#         "-hls_list_size", "0",        # 0 = conserver tous les segments dans la playlist
#         "-hls_flags", "append_list",  # Ajouter √† la playlist au lieu de la remplacer
#         "-hls_segment_filename", f"{HLS_OUTPUT_DIR}/segment_%03d.ts",
#         f"{HLS_OUTPUT_DIR}/playlist.m3u8"
#     ]
    
#     logger.info(f"D√©marrage de la conversion RTSP vers HLS: {' '.join(ffmpeg_cmd)}")
    
#     with process_lock:
#         if restart_event.is_set():
#             return
            
#         # Arr√™t propre de l'ancien processus
#         if current_process:
#             try:
#                 current_process.terminate()
#                 current_process.wait(timeout=5)
#             except:
#                 pass
        
#         # D√©marrage du nouveau processus
#         current_process = subprocess.Popen(
#             ffmpeg_cmd,
#             stdin=subprocess.PIPE,
#             stdout=subprocess.PIPE,
#             stderr=subprocess.PIPE,
#             universal_newlines=True
#         )
#         active_rtsp_url = rtsp_url
    
#     # Surveillance du processus
#     while not restart_event.is_set():
#         retcode = current_process.poll()
#         if retcode is not None:
#             logger.warning(f"FFmpeg s'est arr√™t√© (code: {retcode})")
#             stderr_output = current_process.stderr.read()
#             if stderr_output:
#                 logger.error(f"Erreur FFmpeg: {stderr_output}")
#             time.sleep(2)
#             # Red√©marrer le processus en cas d'erreur
#             start_hls_conversion(rtsp_url)
#             break
        
#         time.sleep(1)

# @app.get("/api/start")
# async def start_processing(
#     rtsp_url: str = Query(..., description="URL RTSP √† convertir en HLS"),
#     enable_ai: bool = Query(True, description="Activer la d√©tection AI")
# ):
#     """D√©marre ou met √† jour la conversion RTSP vers HLS"""
#     global restart_event, ai_enabled
    
#     # Validation de l'URL
#     if not rtsp_url.startswith("rtsp://"):
#         raise HTTPException(status_code=400, detail="URL RTSP invalide")
    
#     ai_enabled = enable_ai
    
#     # Signal de red√©marrage
#     restart_event.set()
#     time.sleep(1)  # Attente pour l'arr√™t propre
#     restart_event.clear()
    
#     # D√©marrer le thread de conversion HLS
#     threading.Thread(
#         target=start_hls_conversion,
#         args=(rtsp_url,),
#         daemon=True
#     ).start()
    
#     # D√©marrer le thread de d√©tection AI si activ√©
#     if ai_enabled and (yolo_model is not None):
#         threading.Thread(
#             target=ai_detection_thread,
#             args=(rtsp_url,),
#             daemon=True
#         ).start()
    
#     return JSONResponse({
#         "status": "Conversion d√©marr√©e",
#         "rtsp_url": rtsp_url,
#         "hls_url": f"http://localhost:{HTTP_PORT}/hls/playlist.m3u8",
#         "ai_enabled": ai_enabled
#     })

# @app.get("/api/stop")
# async def stop_processing():
#     """Arr√™te compl√®tement le processus"""
#     global current_process, restart_event
    
#     restart_event.set()
#     with process_lock:
#         if current_process:
#             try:
#                 current_process.terminate()
#                 current_process.wait(timeout=5)
#             except:
#                 pass
#             current_process = None
    
#     return JSONResponse({"status": "Flux HLS arr√™t√©"})

# @app.get("/api/status")
# async def get_status():
#     """Retourne le statut actuel"""
#     is_active = False
#     with process_lock:
#         if current_process and current_process.poll() is None:
#             is_active = True
    
#     # V√©rifier si le fichier playlist existe
#     playlist_exists = os.path.exists(f"{HLS_OUTPUT_DIR}/playlist.m3u8")
    
#     # Compter les segments .ts
#     ts_segments = [f for f in os.listdir(HLS_OUTPUT_DIR) if f.endswith('.ts')]
    
#     return JSONResponse({
#         "active": is_active,
#         "current_rtsp_url": active_rtsp_url,
#         "hls_playlist_exists": playlist_exists,
#         "segment_count": len(ts_segments),
#         "segments": sorted(ts_segments)[:10] + ["..."] if len(ts_segments) > 10 else sorted(ts_segments),
#         "ai_enabled": ai_enabled,
#         "ai_detection": detection_results if ai_enabled else None
#     })

# @app.get("/api/analytics/image")
# async def get_latest_detection():
#     """Retourne la derni√®re image avec d√©tection"""
#     image_path = f"{HLS_ANALYTICS_DIR}/latest_detection.jpg"
    
#     if os.path.exists(image_path):
#         return FileResponse(image_path)
#     else:
#         raise HTTPException(status_code=404, detail="Image de d√©tection non disponible")

# @app.get("/api/cleanup")
# async def cleanup_segments(
#     keep_last: int = Query(0, description="Nombre de segments r√©cents √† conserver (0 pour tout garder)")
# ):
#     """Nettoie les anciens segments tout en pr√©servant les plus r√©cents"""
#     try:
#         ts_segments = sorted([f for f in os.listdir(HLS_OUTPUT_DIR) if f.endswith('.ts')])
        
#         if keep_last > 0 and len(ts_segments) > keep_last:
#             segments_to_delete = ts_segments[:-keep_last]
#             for segment in segments_to_delete:
#                 segment_path = os.path.join(HLS_OUTPUT_DIR, segment)
#                 os.remove(segment_path)
#             return JSONResponse({
#                 "status": "Nettoyage effectu√©",
#                 "segments_deleted": len(segments_to_delete),
#                 "segments_kept": min(keep_last, len(ts_segments))
#             })
#         else:
#             return JSONResponse({
#                 "status": "Aucun nettoyage n√©cessaire",
#                 "segment_count": len(ts_segments)
#             })
#     except Exception as e:
#         logger.error(f"Erreur lors du nettoyage des segments: {str(e)}")
#         return JSONResponse({
#             "status": "Erreur lors du nettoyage",
#             "error": str(e)
#         }, status_code=500)

# # Montage des fichiers statiques pour l'acc√®s HLS
# app.mount("/hls", StaticFiles(directory=HLS_OUTPUT_DIR), name="hls")

# @app.on_event("startup")
# async def startup_event():
#     """Actions √† ex√©cuter au d√©marrage"""
#     # Nettoyer les fichiers HLS existants
#     if os.path.exists(HLS_OUTPUT_DIR):
#         for item in os.listdir(HLS_OUTPUT_DIR):
#             item_path = os.path.join(HLS_OUTPUT_DIR, item)
#             if os.path.isfile(item_path) and (item.endswith('.ts') or item.endswith('.m3u8')):
#                 os.unlink(item_path)
    
#     # Nettoyer les fichiers d'analyse
#     if os.path.exists(HLS_ANALYTICS_DIR):
#         for item in os.listdir(HLS_ANALYTICS_DIR):
#             item_path = os.path.join(HLS_ANALYTICS_DIR, item)
#             if os.path.isfile(item_path):
#                 os.unlink(item_path)

# if __name__ == '__main__':
#     import uvicorn
#     uvicorn.run(app, host='0.0.0.0', port=HTTP_PORT, log_level="info")



#################### teste  ######################


# import os
# import subprocess
# import threading
# import time
# import cv2
# import numpy as np
# import logging
# from pathlib import Path
# from fastapi import FastAPI, Query, HTTPException
# from fastapi.responses import JSONResponse, FileResponse
# from fastapi.staticfiles import StaticFiles
# from ultralytics import YOLO
# import shutil
# import queue

# # Configuration du logging
# logging.basicConfig(level=logging.INFO)
# logger = logging.getLogger(__name__)

# app = FastAPI(title="RTSP to HLS Converter with AI Detection and Storage")

# # Configuration
# HLS_OUTPUT_DIR = "tmp/hls_output"
# HLS_ANALYTICS_DIR = f"{HLS_OUTPUT_DIR}/analytics"
# HTTP_PORT = 8020
# PIPE_PATH = "tmp/ffmpeg_pipe.yuv"

# # S'assurer que les r√©pertoires existent
# Path(HLS_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
# Path(HLS_ANALYTICS_DIR).mkdir(parents=True, exist_ok=True)
# Path(os.path.dirname(PIPE_PATH)).mkdir(parents=True, exist_ok=True)

# # Charger les mod√®les YOLO une seule fois au d√©marrage
# try:
#     yolo_model = YOLO("yolov8n.pt")  # Mod√®le g√©n√©ral pour la d√©tection d'objets
#     face_model = YOLO("yolov8n-face.pt")  # Mod√®le sp√©cifique pour la d√©tection de visages
#     logger.info("Mod√®les YOLO charg√©s avec succ√®s")
# except Exception as e:
#     logger.error(f"Erreur lors du chargement des mod√®les YOLO: {str(e)}")
#     yolo_model = None
#     face_model = None

# # Variables globales
# current_process = None
# frame_queue = queue.Queue(maxsize=30)  # Pour la communication entre threads
# process_lock = threading.Lock()
# restart_event = threading.Event()
# active_rtsp_url = None
# ai_enabled = True
# detection_results = {
#     "objects": {},
#     "faces": 0,
#     "last_update": None
# }

# # Liste des transports RTSP √† essayer
# rtsp_transports = ["tcp", "udp", "http", "udp_multicast"]

# def draw_boxes(frame, results, is_face=False):
#     """Dessine les bo√Ætes de d√©tection sur l'image"""
#     annotated_frame = frame.copy()
    
#     if results.boxes:
#         for box in results.boxes:
#             # R√©cup√©rer les coordonn√©es et la classe
#             x1, y1, x2, y2 = map(int, box.xyxy[0])
#             conf = float(box.conf[0])
            
#             if is_face:
#                 # Rouge pour les visages
#                 color = (0, 0, 255)
#                 label = f"Face: {conf:.2f}"
#             else:
#                 # Vert pour les objets
#                 color = (0, 255, 0)
#                 cls = int(box.cls[0])
#                 class_name = results.names[cls]
#                 label = f"{class_name}: {conf:.2f}"
            
#             # Dessiner la bo√Æte
#             cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
            
#             # Ajouter le texte
#             cv2.putText(
#                 annotated_frame, 
#                 label, 
#                 (x1, y1 - 10), 
#                 cv2.FONT_HERSHEY_SIMPLEX, 
#                 0.5, 
#                 color, 
#                 2
#             )
    
#     return annotated_frame

# def rtsp_reader_thread(rtsp_url):
#     """Thread am√©lior√© avec gestion robuste des connexions RTSP"""
#     global detection_results
    
#     logger.info(f"D√©marrage du thread de lecture RTSP pour: {rtsp_url}")
    
#     # Configuration
#     max_retries = 5  # Augmentez le nombre de tentatives
#     retry_delay = 5
#     frame_timeout = 30  # Augmentez le timeout
    
#     while not restart_event.is_set():
#         cap = None
#         ffmpeg_process = None
#         last_frame_time = time.time()
        
#         try:
#             # Phase de connexion avec r√©essais
#             for attempt in range(max_retries):
#                 if restart_event.is_set():
#                     break
                    
#                 try:
#                     # Essayer diff√©rents transports
#                     for transport in rtsp_transports:
#                         try:
#                             logger.info(f"Tentative {attempt+1}/{max_retries} avec transport {transport}")
#                             os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = f"rtsp_transport;{transport}"
                            
#                             # Ouvrir le flux avec timeout
#                             cap = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)
#                             cap.set(cv2.CAP_PROP_OPEN_TIMEOUT_MSEC, 30000)  # 30s timeout
                            
#                             if not cap.isOpened():
#                                 raise Exception("√âchec d'ouverture du flux")
                                
#                             # Configurer le buffer minimum
#                             cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
#                             cap.set(cv2.CAP_PROP_FPS, 30)
                            
#                             width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#                             height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#                             fps = cap.get(cv2.CAP_PROP_FPS) or 25.0
                            
#                             logger.info(f"Connexion √©tablie: {width}x{height}@{fps}fps")
                            
#                             # Configurer FFmpeg
#                             ffmpeg_process = configure_ffmpeg(width, height, fps)
#                             if not ffmpeg_process:
#                                 raise Exception("√âchec configuration FFmpeg")
                            
#                             break  # Sortir de la boucle si succ√®s
                            
#                         except Exception as e:
#                             logger.warning(f"√âchec transport {transport}: {str(e)}")
#                             if cap:
#                                 cap.release()
#                             time.sleep(1)
#                     else:
#                         continue  # Si aucun transport n'a fonctionn√©
                    
#                     break  # Sortir de la boucle de r√©essais si succ√®s
                    
#                 except Exception as e:
#                     logger.error(f"Tentative {attempt+1} √©chou√©e: {str(e)}")
#                     if attempt < max_retries - 1:
#                         time.sleep(retry_delay)
            
#             # V√©rifier que la capture est ouverte
#             if not cap or not cap.isOpened() or not ffmpeg_process:
#                 logger.error("√âchec apr√®s toutes les tentatives de connexion")
#                 time.sleep(5)  # Attendre avant de r√©essayer
#                 continue
                
#             # Boucle principale de traitement des images
#             frame_count = 0
#             consecutive_errors = 0
#             last_detection_time = time.time() - 10  # Pour forcer une d√©tection imm√©diate
#             annotated_frame = None  # Pour conserver la derni√®re frame annot√©e
            
#             while not restart_event.is_set():
#                 try:
#                     # Lire une frame
#                     ret, frame = cap.read()
                    
#                     if not ret:
#                         consecutive_errors += 1
#                         logger.warning(f"√âchec de lecture de frame ({consecutive_errors}/10)")
#                         if consecutive_errors >= 10:
#                             logger.error("Trop d'erreurs cons√©cutives, reconnexion...")
#                             break
#                         time.sleep(0.1)
#                         continue
                    
#                     # R√©initialiser le compteur d'erreurs si frame re√ßue
#                     consecutive_errors = 0
#                     last_frame_time = time.time()
#                     frame_count += 1
                    
#                     # Pr√©parer la frame √† encoder (par d√©faut, utiliser frame originale)
#                     frame_to_encode = frame.copy()
                    
#                     # Faire la d√©tection AI √† intervalle r√©gulier (toutes les 1 secondes)
#                     if ai_enabled and time.time() - last_detection_time > 1.0:
#                         # Effectuer la d√©tection d'objets avec YOLO
#                         object_results = []
#                         if yolo_model:
#                             object_results = yolo_model(frame)
                            
#                             # Mettre √† jour les r√©sultats de d√©tection
#                             objects_detected = {}
#                             for r in object_results:
#                                 if r.boxes:
#                                     for box in r.boxes:
#                                         cls = int(box.cls[0])
#                                         class_name = r.names[cls]
#                                         if class_name in objects_detected:
#                                             objects_detected[class_name] += 1
#                                         else:
#                                             objects_detected[class_name] = 1
                            
#                             detection_results["objects"] = objects_detected
                        
#                         # Effectuer la d√©tection de visages
#                         face_results = []
#                         if face_model:
#                             face_results = face_model(frame)
                            
#                             # Compter les visages
#                             face_count = 0
#                             for r in face_results:
#                                 if r.boxes:
#                                     face_count += len(r.boxes)
                            
#                             detection_results["faces"] = face_count
                        
#                         # Mettre √† jour le timestamp
#                         detection_results["last_update"] = time.strftime("%Y-%m-%d %H:%M:%S")
                        
#                         # Cr√©er une image annot√©e pour visualisation et flux HLS
#                         annotated_frame = frame.copy()
                        
#                         # Appliquer les annotations des objets
#                         if yolo_model:
#                             for r in object_results:
#                                 annotated_frame = draw_boxes(annotated_frame, r, False)
                                
#                         # Appliquer les annotations des visages
#                         if face_model:
#                             for r in face_results:
#                                 annotated_frame = draw_boxes(annotated_frame, r, True)
                        
#                         # Sauvegarder l'image annot√©e dans le dossier analytics
#                         cv2.imwrite(f"{HLS_ANALYTICS_DIR}/latest_detection.jpg", annotated_frame)
                        
#                         # Utiliser cette frame annot√©e pour l'encodage HLS
#                         frame_to_encode = annotated_frame
                        
#                         # Mettre √† jour le timestamp de derni√®re d√©tection
#                         last_detection_time = time.time()
#                     elif ai_enabled and annotated_frame is not None:
#                         # Entre les d√©tections, utiliser la derni√®re frame annot√©e comme base
#                         # mais mettre √† jour avec la nouvelle image
#                         current_frame = frame.copy()
#                         h, w = current_frame.shape[:2]
#                         annotated_h, annotated_w = annotated_frame.shape[:2]
                        
#                         # S'assurer que les dimensions correspondent
#                         if h == annotated_h and w == annotated_w:
#                             # Superposer les d√©tections de la frame annot√©e sur la frame actuelle
#                             # D√©tection des bo√Ætes de couleur dans la frame annot√©e
#                             diff = cv2.absdiff(frame, annotated_frame)
#                             mask = np.any(diff > 50, axis=2).astype(np.uint8) * 255
                            
#                             # Dilater le masque pour prendre les bo√Ætes compl√®tes
#                             kernel = np.ones((5, 5), np.uint8)
#                             mask = cv2.dilate(mask, kernel, iterations=2)
                            
#                             # Fusionner les zones significatives des deux images
#                             alpha = 0.7
#                             frame_to_encode = cv2.addWeighted(frame, 1.0, annotated_frame, alpha, 0)
#                         else:
#                             # Si les dimensions ne correspondent pas, utiliser juste la nouvelle frame
#                             frame_to_encode = frame.copy()
                    
#                     # Encoder la frame pour FFmpeg
#                     _, encoded_frame = cv2.imencode('.jpg', frame_to_encode, [cv2.IMWRITE_JPEG_QUALITY, 90])
                    
#                     # V√©rifier si FFmpeg est toujours en cours d'ex√©cution
#                     if ffmpeg_process.poll() is not None:
#                         logger.error("FFmpeg s'est arr√™t√© de fa√ßon inattendue, red√©marrage...")
#                         break
                    
#                     # Envoyer la frame √† FFmpeg
#                     try:
#                         ffmpeg_process.stdin.write(encoded_frame.tobytes())
#                         ffmpeg_process.stdin.flush()
#                     except (BrokenPipeError, IOError) as e:
#                         logger.error(f"Erreur d'√©criture vers FFmpeg: {str(e)}")
#                         break
                    
#                     # V√©rifier si on n'a pas re√ßu de frame depuis longtemps
#                     if time.time() - last_frame_time > frame_timeout:
#                         logger.warning(f"Aucune frame re√ßue depuis {frame_timeout} secondes, reconnexion...")
#                         break
                    
#                     # Contr√¥le de d√©bit pour √©viter de surcharger le syst√®me
#                     if frame_count % 100 == 0:
#                         logger.info(f"Frames trait√©es: {frame_count}")
                    
#                 except Exception as e:
#                     logger.error(f"Erreur dans la boucle de traitement: {str(e)}")
#                     time.sleep(1)
                    
#         except Exception as e:
#             logger.error(f"Erreur dans le thread de lecture RTSP: {str(e)}")
        
#         # Nettoyage
#         try:
#             if cap:
#                 cap.release()
            
#             if ffmpeg_process and ffmpeg_process.poll() is None:
#                 try:
#                     ffmpeg_process.stdin.close()
#                     ffmpeg_process.wait(timeout=5)
#                 except Exception as e:
#                     logger.warning(f"Impossible de fermer proprement FFmpeg: {str(e)}")
#                     ffmpeg_process.kill()
#         except Exception as e:
#             logger.error(f"Erreur lors du nettoyage: {str(e)}")
        
#         # Attendre avant de r√©essayer
#         if not restart_event.is_set():
#             logger.info("Attente avant reconnexion...")
#             time.sleep(5)

# def configure_ffmpeg(width, height, fps):
#     """Configure FFmpeg avec des param√®tres plus robustes"""
#     try:
#         ffmpeg_cmd = [
#             "ffmpeg",
#             "-hide_banner",
#             "-loglevel", "error",
#             "-f", "image2pipe",
#             "-framerate", str(fps),
#             "-i", "-",
#             "-c:v", "libx264",
#             "-preset", "ultrafast",
#             "-tune", "zerolatency",
#             "-b:v", "2M",
#             "-hls_time", "2",
#             "-hls_list_size", "0",  # Valeur 0 pour garder tous les segments dans la playlist
#             "-hls_flags", "append_list",  # Supprimer delete_segments pour conserver les segments
#             "-hls_segment_filename", f"{HLS_OUTPUT_DIR}/segment_%06d.ts",  # Format avec plus de chiffres pour supporter plus de segments
#             f"{HLS_OUTPUT_DIR}/playlist.m3u8"
#         ]
        
#         logger.info(f"Configuration FFmpeg: {' '.join(ffmpeg_cmd)}")
        
#         return subprocess.Popen(
#             ffmpeg_cmd,
#             stdin=subprocess.PIPE,
#             stdout=subprocess.PIPE,
#             stderr=subprocess.PIPE,
#             bufsize=10**8  # Buffer tr√®s important
#         )
#     except Exception as e:
#         logger.error(f"Erreur configuration FFmpeg: {str(e)}")
#         return None

# def start_hls_conversion_with_detection(rtsp_url):
#     """D√©marre la conversion RTSP vers HLS avec d√©tection AI int√©gr√©e"""
#     global current_process, active_rtsp_url
    
#     # Pr√©parer le r√©pertoire sans supprimer les fichiers existants
#     prepare_hls_directory()
    
#     # D√©marrer le thread de lecture RTSP avec d√©tection AI
#     threading.Thread(
#         target=rtsp_reader_thread,
#         args=(rtsp_url,),
#         daemon=True
#     ).start()
    
#     active_rtsp_url = rtsp_url

# def prepare_hls_directory():
#     """Pr√©pare le r√©pertoire HLS sans supprimer les fichiers existants"""
#     try:
#         # S'assurer que les r√©pertoires existent
#         Path(HLS_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
#         Path(HLS_ANALYTICS_DIR).mkdir(parents=True, exist_ok=True)
        
#         # Optionnel: archiver l'ancienne playlist.m3u8 si elle existe
#         playlist_path = os.path.join(HLS_OUTPUT_DIR, "playlist.m3u8")
#         if os.path.exists(playlist_path):
#             timestamp = time.strftime("%Y%m%d-%H%M%S")
#             archive_path = os.path.join(HLS_OUTPUT_DIR, f"playlist_archive_{timestamp}.m3u8")
#             shutil.copy2(playlist_path, archive_path)
#             logger.info(f"Playlist existante archiv√©e sous: {archive_path}")
        
#         logger.info("R√©pertoire HLS pr√©par√©")
#     except Exception as e:
#         logger.error(f"Erreur lors de la pr√©paration du r√©pertoire HLS: {str(e)}")

# @app.get("/api/start")
# async def start_processing(
#     rtsp_url: str = Query(..., description="URL RTSP √† convertir en HLS"),
#     enable_ai: bool = Query(True, description="Activer la d√©tection AI")
# ):
#     """D√©marre ou met √† jour la conversion RTSP vers HLS avec d√©tection AI"""
#     global restart_event, ai_enabled
    
#     # Validation de l'URL
#     if not rtsp_url.startswith("rtsp://"):
#         raise HTTPException(status_code=400, detail="URL RTSP invalide")
    
#     ai_enabled = enable_ai
    
#     # Signal de red√©marrage
#     restart_event.set()
#     time.sleep(1)  # Attente pour l'arr√™t propre
#     restart_event.clear()
    
#     # D√©marrer la conversion avec d√©tection AI
#     start_hls_conversion_with_detection(rtsp_url)
    
#     return JSONResponse({
#         "status": "Conversion avec AI int√©gr√©e d√©marr√©e",
#         "rtsp_url": rtsp_url,
#         "hls_url": f"http://localhost:{HTTP_PORT}/hls/playlist.m3u8",
#         "ai_enabled": ai_enabled
#     })

# @app.get("/api/stop")
# async def stop_processing():
#     """Arr√™te le processus de conversion sans nettoyer les fichiers"""
#     global restart_event, active_rtsp_url
    
#     restart_event.set()
#     time.sleep(1)  # Attendre l'arr√™t propre des threads
#     active_rtsp_url = None
    
#     return JSONResponse({
#         "status": "Flux HLS arr√™t√© (fichiers conserv√©s)",
#         "segments_directory": HLS_OUTPUT_DIR
#     })

# @app.get("/api/clean")
# async def clean_files():
#     """Nettoie tous les fichiers HLS (segments et playlist) et le dossier analytics"""
#     try:
#         # Supprimer tous les fichiers .ts et .m3u8
#         for file in os.listdir(HLS_OUTPUT_DIR):
#             file_path = os.path.join(HLS_OUTPUT_DIR, file)
#             if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
#                 os.remove(file_path)
        
#         # Nettoyer le dossier analytics
#         analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
#         if os.path.exists(analytics_dir):
#             for file in os.listdir(analytics_dir):
#                 file_path = os.path.join(analytics_dir, file)
#                 if os.path.isfile(file_path):
#                     os.remove(file_path)
        
#         logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√©")
        
#         return JSONResponse({"status": "Tous les fichiers HLS et analytics ont √©t√© supprim√©s"})
#     except Exception as e:
#         logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")
#         return JSONResponse({
#             "status": "Erreur lors du nettoyage",
#             "error": str(e)
#         }, status_code=500)

# @app.get("/api/status")
# async def get_status():
#     """Retourne le statut actuel"""
#     is_active = not restart_event.is_set() and active_rtsp_url is not None
    
#     # V√©rifier si le fichier playlist existe
#     playlist_exists = os.path.exists(f"{HLS_OUTPUT_DIR}/playlist.m3u8")
    
#     # Compter les segments .ts
#     ts_segments = [f for f in os.listdir(HLS_OUTPUT_DIR) if f.endswith('.ts')]
    
#     # Calculer l'espace disque utilis√©
#     total_size_bytes = 0
#     for segment in ts_segments:
#         segment_path = os.path.join(HLS_OUTPUT_DIR, segment)
#         total_size_bytes += os.path.getsize(segment_path)
    
#     total_size_mb = total_size_bytes / (1024 * 1024)
    
#     return JSONResponse({
#         "active": is_active,
#         "current_rtsp_url": active_rtsp_url,
#         "hls_playlist_exists": playlist_exists,
#         "segment_count": len(ts_segments),
#         "segments": sorted(ts_segments)[:10] + ["..."] if len(ts_segments) > 10 else sorted(ts_segments),
#         "ai_enabled": ai_enabled,
#         "ai_detection": detection_results if ai_enabled else None,
#         "disk_usage_mb": round(total_size_mb, 2)
#     })

# @app.get("/api/analytics/image")
# async def get_latest_detection():
#     """Retourne la derni√®re image avec d√©tection"""
#     image_path = f"{HLS_ANALYTICS_DIR}/latest_detection.jpg"
    
#     if os.path.exists(image_path):
#         return FileResponse(image_path)
#     else:
#         raise HTTPException(status_code=404, detail="Image de d√©tection non disponible")

# @app.get("/api/cleanup")
# async def cleanup_segments(
#     keep_last: int = Query(0, description="Nombre de segments r√©cents √† conserver (0 pour tout garder)")
# ):
#     """Nettoie les anciens segments tout en pr√©servant les plus r√©cents"""
#     try:
#         ts_segments = sorted([f for f in os.listdir(HLS_OUTPUT_DIR) if f.endswith('.ts')])
        
#         if keep_last > 0 and len(ts_segments) > keep_last:
#             segments_to_delete = ts_segments[:-keep_last]
#             for segment in segments_to_delete:
#                 segment_path = os.path.join(HLS_OUTPUT_DIR, segment)
#                 os.remove(segment_path)
            
#             # Nettoyer le dossier analytics si on fait un nettoyage des segments
#             analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
#             if os.path.exists(analytics_dir):
#                 for file in os.listdir(analytics_dir):
#                     file_path = os.path.join(analytics_dir, file)
#                     if os.path.isfile(file_path):
#                         os.remove(file_path)
#                 logger.info("Nettoyage du dossier analytics effectu√©")
            
#             return JSONResponse({
#                 "status": "Nettoyage effectu√©",
#                 "segments_deleted": len(segments_to_delete),
#                 "segments_kept": min(keep_last, len(ts_segments)),
#                 "analytics_cleaned": True
#             })
#         else:
#             return JSONResponse({
#                 "status": "Aucun nettoyage n√©cessaire",
#                 "segment_count": len(ts_segments)
#             })
#     except Exception as e:
#         logger.error(f"Erreur lors du nettoyage des segments: {str(e)}")
#         return JSONResponse({
#             "status": "Erreur lors du nettoyage",
#             "error": str(e)
#         }, status_code=500)

# # Montage des fichiers statiques pour l'acc√®s HLS
# app.mount("/hls", StaticFiles(directory=HLS_OUTPUT_DIR), name="hls")

# @app.on_event("startup")
# async def startup_event():
#     """Actions √† ex√©cuter au d√©marrage"""
#     # Cr√©er les r√©pertoires si n√©cessaire, mais ne pas supprimer les fichiers
#     Path(HLS_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
#     Path(HLS_ANALYTICS_DIR).mkdir(parents=True, exist_ok=True)
#     logger.info("Application d√©marr√©e et pr√™te √† recevoir des connexions")

# if __name__ == '__main__':
#     import uvicorn
#     uvicorn.run(app, host='0.0.0.0', port=HTTP_PORT, log_level="info")










########################################## test 2 ######################################

# ### api_rtsp_to_hls.py
# import os
# import subprocess
# import threading
# import time
# import cv2
# import numpy as np
# import logging
# from pathlib import Path
# from fastapi import FastAPI, Query, HTTPException
# from fastapi.responses import JSONResponse, FileResponse
# from fastapi.staticfiles import StaticFiles
# from ultralytics import YOLO
# import shutil
# import queue
# from collections import defaultdict
# import signal
# import sys




# # Configuration du logging
# logging.basicConfig(level=logging.INFO)
# logger = logging.getLogger(__name__)

# app = FastAPI(title="RTSP to HLS Converter with AI Detection and Tracking")

# # Configuration
# HLS_OUTPUT_DIR = "tmp/hls_output"
# HLS_ANALYTICS_DIR = f"{HLS_OUTPUT_DIR}/analytics"
# HTTP_PORT = 8020
# PIPE_PATH = "tmp/ffmpeg_pipe.yuv"

# # S'assurer que les r√©pertoires existent
# Path(HLS_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
# Path(HLS_ANALYTICS_DIR).mkdir(parents=True, exist_ok=True)
# Path(os.path.dirname(PIPE_PATH)).mkdir(parents=True, exist_ok=True)

# # Charger les mod√®les YOLO une seule fois au d√©marrage
# try:
#     # Utiliser les mod√®les avec le tracking activ√©
#     yolo_model = YOLO("yolov8n.pt")
#     face_model = YOLO("yolov8n-face.pt")
#     logger.info("Mod√®les YOLO charg√©s avec succ√®s")
# except Exception as e:
#     logger.error(f"Erreur lors du chargement des mod√®les YOLO: {str(e)}")
#     yolo_model = None
#     face_model = None

# # Variables globales
# current_process = None
# detection_queue = queue.Queue(maxsize=10)  # File d'attente pour les d√©tections
# process_lock = threading.Lock()
# restart_event = threading.Event()
# active_rtsp_url = None
# ai_enabled = True
# detection_results = {
#     "objects": {},
#     "faces": 0,
#     "last_update": None,
#     "tracked_objects": {}  # Pour stocker les objets suivis avec leurs IDs
# }





# def signal_handler(sig, frame):
#     """Gestionnaire de signal pour l'arr√™t propre de l'application"""
#     logger.info("Signal d'arr√™t re√ßu, nettoyage en cours...")
    
#     # Nettoyer tous les fichiers du dossier HLS
#     try:
#         # Supprimer tous les fichiers .ts et .m3u8
#         for file in os.listdir(HLS_OUTPUT_DIR):
#             file_path = os.path.join(HLS_OUTPUT_DIR, file)
#             if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
#                 os.remove(file_path)
        
#         # Nettoyer le dossier analytics
#         analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
#         if os.path.exists(analytics_dir):
#             for file in os.listdir(analytics_dir):
#                 file_path = os.path.join(analytics_dir, file)
#                 if os.path.isfile(file_path):
#                     os.remove(file_path)
        
#         logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√©")
#     except Exception as e:
#         logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")
    
#     sys.exit(0)

# # Enregistrer le gestionnaire de signal
# signal.signal(signal.SIGINT, signal_handler)  # Ctrl+C
# signal.signal(signal.SIGTERM, signal_handler)  # kill



# # Liste des transports RTSP √† essayer
# rtsp_transports = ["tcp", "udp", "http", "udp_multicast"]

# def draw_boxes_with_tracking(frame, results):
#     """Dessine les bo√Ætes de d√©tection avec IDs de tracking sur l'image avec un meilleur rendu"""
#     annotated_frame = frame.copy()
    
#     # Extraire les IDs de tracking et les bo√Ætes
#     if hasattr(results, 'boxes') and results.boxes:
#         for box in results.boxes:
#             # R√©cup√©rer les coordonn√©es et la classe
#             x1, y1, x2, y2 = map(int, box.xyxy[0])
#             conf = float(box.conf[0])
#             cls = int(box.cls[0])
#             class_name = results.names[cls]
            
#             # Couleurs bas√©es sur la classe
#             if class_name == "person":
#                 color = (0, 255, 0)  # Vert pour les personnes
#             elif "face" in class_name.lower():
#                 color = (0, 0, 255)  # Rouge pour les visages
#             else:
#                 color = (255, 0, 0)  # Bleu pour les autres objets
            
#             # R√©cup√©rer l'ID de tracking si disponible
#             track_id = None
#             if hasattr(box, 'id') and box.id is not None:
#                 track_id = int(box.id[0])
#                 # Mettre √† jour les objets suivis dans detection_results
#                 if track_id not in detection_results["tracked_objects"]:
#                     detection_results["tracked_objects"][track_id] = {
#                         "class": class_name,
#                         "first_seen": time.time(),
#                         "last_seen": time.time(),
#                         "position": (int((x1+x2)/2), int((y1+y2)/2))
#                     }
#                 else:
#                     detection_results["tracked_objects"][track_id]["last_seen"] = time.time()
#                     detection_results["tracked_objects"][track_id]["position"] = (int((x1+x2)/2), int((y1+y2)/2))
                
#                 label = f"{class_name} #{track_id}: {conf:.2f}"
#             else:
#                 label = f"{class_name}: {conf:.2f}"
            
#             # Dessiner la bo√Æte avec une ligne plus fine pour moins d√©grader l'image
#             cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)  # √âpaisseur r√©duite √† 2
            
#             # Fond semi-transparent pour le texte
#             text_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
#             cv2.rectangle(annotated_frame, 
#                          (x1, y1 - text_size[1] - 10), 
#                          (x1 + text_size[0], y1), 
#                          color, -1)  # Remplir le rectangle
            
#             # Ajouter le texte avec une meilleure visibilit√©
#             cv2.putText(
#                 annotated_frame, 
#                 label, 
#                 (x1, y1 - 5), 
#                 cv2.FONT_HERSHEY_SIMPLEX, 
#                 0.5, 
#                 (255, 255, 255),  # Texte blanc pour contraste
#                 1  # √âpaisseur r√©duite
#             )
    
#     return annotated_frame

# def detection_worker():
#     """Thread d√©di√© √† l'analyse d'images pour ne pas bloquer le flux vid√©o"""
#     global detection_results
    
#     logger.info("D√©marrage du thread de d√©tection AI")
    
#     detection_queue.maxsize = 5  # R√©duit la taille de la file pour √©viter l'accumulation
#     last_annotated_hash = None  # Pour v√©rifier les changements dans la frame annot√©e
    
#     while not restart_event.is_set():
#         try:
#             if detection_queue.empty():
#                 time.sleep(0.01)
#                 continue
                
#             frame = detection_queue.get()
            
#             objects_detected = defaultdict(int)
#             face_count = 0
#             annotated_frame = frame.copy()
            
#             if yolo_model:
#                 object_results = yolo_model.track(frame, persist=True, tracker="bytetrack.yaml")
#                 for r in object_results:
#                     annotated_frame = draw_boxes_with_tracking(annotated_frame, r)
#                     if r.boxes:
#                         for box in r.boxes:
#                             cls = int(box.cls[0])
#                             class_name = r.names[cls]
#                             objects_detected[class_name] += 1
            
#             if face_model:
#                 face_results = face_model.track(frame, persist=True, tracker="bytetrack.yaml")
#                 for r in face_results:
#                     annotated_frame = draw_boxes_with_tracking(annotated_frame, r)
#                     if r.boxes:
#                         face_count += len(r.boxes)
            
#             detection_results["objects"] = dict(objects_detected)
#             detection_results["faces"] = face_count
#             detection_results["last_update"] = time.strftime("%Y-%m-%d %H:%M:%S")
            
#             current_time = time.time()
#             to_remove = []
#             for track_id, obj_info in detection_results["tracked_objects"].items():
#                 if current_time - obj_info["last_seen"] > 5.0:
#                     to_remove.append(track_id)
            
#             for track_id in to_remove:
#                 del detection_results["tracked_objects"][track_id]
            
#             # Calculer un hash simple de la frame annot√©e pour v√©rifier les changements
#             import hashlib
#             frame_hash = hashlib.md5(annotated_frame.tobytes()).hexdigest()
            
#             # Sauvegarder uniquement si la frame a chang√©
#             if frame_hash != last_annotated_hash:
#                 with open(f"{HLS_ANALYTICS_DIR}/annotated_frame.npy", 'wb') as f:
#                     np.save(f, annotated_frame)
#                 last_annotated_hash = frame_hash
                
#         except Exception as e:
#             logger.error(f"Erreur dans le thread de d√©tection: {str(e)}")
#             time.sleep(0.1)

# def rtsp_reader_thread(rtsp_url):
#     """Thread am√©lior√© avec meilleure gestion de flux et tracking"""
#     global detection_results
    
#     logger.info(f"D√©marrage du thread de lecture RTSP pour: {rtsp_url}")
    
#     # Configuration
#     max_retries = 5
#     retry_delay = 5
#     frame_timeout = 30
#     detection_interval = 0.2  # Analyser toutes les 0.2 secondes au lieu de 1 seconde
    
#     # D√©marrer le thread de d√©tection AI s√©par√©
#     detection_thread = threading.Thread(target=detection_worker, daemon=True)
#     detection_thread.start()
    
#     while not restart_event.is_set():
#         cap = None
#         ffmpeg_process = None
#         last_frame_time = time.time()
        
#         try:
#             # Phase de connexion avec r√©essais
#             for attempt in range(max_retries):
#                 if restart_event.is_set():
#                     break
                    
#                 try:
#                     # Essayer diff√©rents transports
#                     for transport in rtsp_transports:
#                         try:
#                             logger.info(f"Tentative {attempt+1}/{max_retries} avec transport {transport}")
#                             os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = f"rtsp_transport;{transport}"
                            
#                             # Ouvrir le flux avec timeout
#                             cap = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)
#                             cap.set(cv2.CAP_PROP_OPEN_TIMEOUT_MSEC, 10000)  # R√©duit de 30000 √† 10000
#                             cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Buffer minimal
#                             cap.set(cv2.CAP_PROP_FPS, 30)
                            
#                             if not cap.isOpened():
#                                 raise Exception("√âchec d'ouverture du flux")
                            
#                             width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#                             height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#                             fps = cap.get(cv2.CAP_PROP_FPS) or 25.0
                            
#                             logger.info(f"Connexion √©tablie: {width}x{height}@{fps}fps")
                            
#                             # Configurer FFmpeg
#                             ffmpeg_process = configure_ffmpeg(width, height, fps)
#                             if not ffmpeg_process:
#                                 raise Exception("√âchec configuration FFmpeg")
                            
#                             break  # Sortir de la boucle si succ√®s
                            
#                         except Exception as e:
#                             logger.warning(f"√âchec transport {transport}: {str(e)}")
#                             if cap:
#                                 cap.release()
#                             time.sleep(1)
#                     else:
#                         continue  # Si aucun transport n'a fonctionn√©
                        
#                     break  # Sortir de la boucle de r√©essais si succ√®s
                    
#                 except Exception as e:
#                     logger.error(f"Tentative {attempt+1} √©chou√©e: {str(e)}")
#                     if attempt < max_retries - 1:
#                         time.sleep(retry_delay)
            
#             # V√©rifier que la capture est ouverte
#             if not cap or not cap.isOpened() or not ffmpeg_process:
#                 logger.error("√âchec apr√®s toutes les tentatives de connexion")
#                 time.sleep(5)  # Attendre avant de r√©essayer
#                 continue
                
#             # Boucle principale de traitement des images
#             frame_count = 0
#             consecutive_errors = 0
#             last_detection_time = time.time() - 10  # Pour forcer une d√©tection imm√©diate
#             last_annotated_frame = None

#             while not restart_event.is_set():
#                 try:
#                     # Lire une frame
#                     ret, frame = cap.read()
                    
#                     if not ret:
#                         consecutive_errors += 1
#                         logger.warning(f"√âchec de lecture de frame ({consecutive_errors}/10)")
#                         if consecutive_errors >= 10:
#                             logger.error("Trop d'erreurs cons√©cutives, reconnexion...")
#                             break
#                         time.sleep(0.1)
#                         continue
                    
#                     # R√©initialiser le compteur d'erreurs si frame re√ßue
#                     consecutive_errors = 0
#                     last_frame_time = time.time()
#                     frame_count += 1
                    
#                     # Pr√©parer la frame √† encoder
#                     frame_to_encode = frame.copy()
                    
#                     # Faire la d√©tection AI √† intervalle r√©gulier (toutes les 0.2 secondes)
#                     if ai_enabled and time.time() - last_detection_time > detection_interval:
#                         # Ajouter la frame √† la file d'attente pour traitement
#                         if detection_queue.full():
#                             try:
#                                 detection_queue.get_nowait()
#                             except:
#                                 pass
                        
#                         try:
#                             detection_queue.put(frame.copy(), block=False)
#                         except:
#                             pass  # Ignorer si la file est pleine
                        
#                         last_detection_time = time.time()
                    
#                     # Si AI est activ√©e, attendre une frame annot√©e r√©cente
#                     if ai_enabled:
#                         annotated_path = f"{HLS_ANALYTICS_DIR}/annotated_frame.npy"
#                         if os.path.exists(annotated_path):
#                             try:
#                                 file_mtime = os.path.getmtime(annotated_path)
#                                 if time.time() - file_mtime < 0.5:  # Frame annot√©e r√©cente (moins de 0.5s)
#                                     with open(annotated_path, 'rb') as f:
#                                         last_annotated_frame = np.load(f)
#                             except Exception as e:
#                                 logger.warning(f"Erreur lors du chargement de la frame annot√©e: {str(e)}")
                        
#                         # Utiliser la frame annot√©e si disponible et compatible
#                         if last_annotated_frame is not None and last_annotated_frame.shape == frame.shape:
#                             frame_to_encode = last_annotated_frame.copy()
                    
#                     # Encoder la frame pour FFmpeg
#                     _, encoded_frame = cv2.imencode('.jpg', frame_to_encode, [cv2.IMWRITE_JPEG_QUALITY, 95])  # R√©duit √† 95 pour √©quilibrer qualit√©/taille
                    
#                     # V√©rifier si FFmpeg est toujours en cours d'ex√©cution
#                     if ffmpeg_process.poll() is not None:
#                         logger.error("FFmpeg s'est arr√™t√© de fa√ßon inattendue, red√©marrage...")
#                         break
                    
#                     # Envoyer la frame √† FFmpeg
#                     try:
#                         ffmpeg_process.stdin.write(encoded_frame.tobytes())
#                         ffmpeg_process.stdin.flush()
#                     except (BrokenPipeError, IOError) as e:
#                         logger.error(f"Erreur d'√©criture vers FFmpeg: {str(e)}")
#                         break
                    
#                     # V√©rifier si on n'a pas re√ßu de frame depuis longtemps
#                     if time.time() - last_frame_time > frame_timeout:
#                         logger.warning(f"Aucune frame re√ßue depuis {frame_timeout} secondes, reconnexion...")
#                         break
                    
#                     # Contr√¥le de d√©bit pour √©viter de surcharger le syst√®me
#                     if frame_count % 100 == 0:
#                         logger.info(f"Frames trait√©es: {frame_count}")
                    
#                 except Exception as e:
#                     logger.error(f"Erreur dans la boucle de traitement: {str(e)}")
#                     time.sleep(1)
                    
#         except Exception as e:
#             logger.error(f"Erreur dans le thread de lecture RTSP: {str(e)}")
        
#         # Nettoyage
#         try:
#             if cap:
#                 cap.release()
            
#             if ffmpeg_process and ffmpeg_process.poll() is None:
#                 try:
#                     ffmpeg_process.stdin.close()
#                     ffmpeg_process.wait(timeout=5)
#                 except Exception as e:
#                     logger.warning(f"Impossible de fermer proprement FFmpeg: {str(e)}")
#                     ffmpeg_process.kill()
#         except Exception as e:
#             logger.error(f"Erreur lors du nettoyage: {str(e)}")
        
#         # Attendre avant de r√©essayer
#         if not restart_event.is_set():
#             logger.info("Attente avant reconnexion...")
#             time.sleep(5)

# def configure_ffmpeg(width, height, fps):
#     """Configure FFmpeg avec des param√®tres optimis√©s pour la fluidit√©"""
#     try:
#         ffmpeg_cmd = [
#             "ffmpeg",
#             "-hide_banner",
#             "-loglevel", "error",
#             "-f", "image2pipe",
#             "-framerate", str(fps),
#             "-i", "-",
#             "-c:v", "libx264",
#             "-preset", "ultrafast",  # Chang√© √† ultrafast pour minimiser le temps d'encodage
#             "-tune", "zerolatency",
#             "-crf", "18",  # Augment√© √† 18 pour r√©duire la charge
#             "-b:v", "5000k",  # Bitrate r√©duit pour plus de fluidit√©
#             "-profile:v", "high",
#             "-pix_fmt", "yuv420p",
#             "-g", str(int(fps * 2)),
#             "-keyint_min", str(int(fps)),
#             "-hls_time", "1",  # R√©duit √† 1s pour moins de latence
#             "-hls_list_size", "0",
#             "-hls_flags", "append_list",
#             "-hls_segment_filename", f"{HLS_OUTPUT_DIR}/segment_%06d.ts",
#             f"{HLS_OUTPUT_DIR}/playlist.m3u8"
#         ]
        
#         logger.info(f"Configuration FFmpeg: {' '.join(ffmpeg_cmd)}")
        
#         return subprocess.Popen(
#             ffmpeg_cmd,
#             stdin=subprocess.PIPE,
#             stdout=subprocess.PIPE,
#             stderr=subprocess.PIPE,
#             bufsize=10**8
#         )
#     except Exception as e:
#         logger.error(f"Erreur configuration FFmpeg: {str(e)}")
#         return None

# def start_hls_conversion_with_detection(rtsp_url):
#     """D√©marre la conversion RTSP vers HLS avec d√©tection AI int√©gr√©e"""
#     global current_process, active_rtsp_url
    
#     # Pr√©parer le r√©pertoire sans supprimer les fichiers existants
#     prepare_hls_directory()
    
#     # D√©marrer le thread de lecture RTSP avec d√©tection AI
#     threading.Thread(
#         target=rtsp_reader_thread,
#         args=(rtsp_url,),
#         daemon=True
#     ).start()
    
#     active_rtsp_url = rtsp_url

# def prepare_hls_directory():
#     """Pr√©pare le r√©pertoire HLS sans supprimer les fichiers existants"""
#     try:
#         # S'assurer que les r√©pertoires existent
#         Path(HLS_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
#         Path(HLS_ANALYTICS_DIR).mkdir(parents=True, exist_ok=True)
        
#         # Optionnel: archiver l'ancienne playlist.m3u8 si elle existe
#         playlist_path = os.path.join(HLS_OUTPUT_DIR, "playlist.m3u8")
#         if os.path.exists(playlist_path):
#             timestamp = time.strftime("%Y%m%d-%H%M%S")
#             archive_path = os.path.join(HLS_OUTPUT_DIR, f"playlist_archive_{timestamp}.m3u8")
#             shutil.copy2(playlist_path, archive_path)
#             logger.info(f"Playlist existante archiv√©e sous: {archive_path}")
        
#         logger.info("R√©pertoire HLS pr√©par√©")
#     except Exception as e:
#         logger.error(f"Erreur lors de la pr√©paration du r√©pertoire HLS: {str(e)}")

# @app.get("/api/start")
# async def start_processing(
#     rtsp_url: str = Query(..., description="URL RTSP √† convertir en HLS"),
#     enable_ai: bool = Query(True, description="Activer la d√©tection AI")
# ):
#     """D√©marre ou met √† jour la conversion RTSP vers HLS avec d√©tection AI"""
#     global restart_event, ai_enabled
    
#     # Validation de l'URL
#     if not rtsp_url.startswith("rtsp://"):
#         raise HTTPException(status_code=400, detail="URL RTSP invalide")
    
#     ai_enabled = enable_ai
    
#     # Signal de red√©marrage
#     restart_event.set()
#     time.sleep(1)  # Attente pour l'arr√™t propre
#     restart_event.clear()
    
#     # Nettoyer tous les fichiers du dossier HLS avant de commencer
#     try:
#         # Supprimer tous les fichiers .ts et .m3u8
#         for file in os.listdir(HLS_OUTPUT_DIR):
#             file_path = os.path.join(HLS_OUTPUT_DIR, file)
#             if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
#                 os.remove(file_path)
        
#         # Nettoyer le dossier analytics
#         analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
#         if os.path.exists(analytics_dir):
#             for file in os.listdir(analytics_dir):
#                 file_path = os.path.join(analytics_dir, file)
#                 if os.path.isfile(file_path):
#                     os.remove(file_path)
        
#         logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√© avant d√©marrage")
#     except Exception as e:
#         logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")
    
#     # D√©marrer la conversion avec d√©tection AI
#     start_hls_conversion_with_detection(rtsp_url)
    
#     return JSONResponse({
#         "status": "Conversion avec AI int√©gr√©e d√©marr√©e",
#         "rtsp_url": rtsp_url,
#         "hls_url": f"http://localhost:{HTTP_PORT}/hls/playlist.m3u8",
#         "ai_enabled": ai_enabled
#     })

# @app.get("/api/stop")
# async def stop_processing():
#     """Arr√™te le processus de conversion et nettoie tous les fichiers"""
#     global restart_event, active_rtsp_url
    
#     restart_event.set()
#     time.sleep(1)  # Attendre l'arr√™t propre des threads
#     active_rtsp_url = None
    
#     # Nettoyer tous les fichiers du dossier HLS
#     try:
#         # Supprimer tous les fichiers .ts et .m3u8
#         for file in os.listdir(HLS_OUTPUT_DIR):
#             file_path = os.path.join(HLS_OUTPUT_DIR, file)
#             if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
#                 os.remove(file_path)
        
#         # Nettoyer le dossier analytics
#         analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
#         if os.path.exists(analytics_dir):
#             for file in os.listdir(analytics_dir):
#                 file_path = os.path.join(analytics_dir, file)
#                 if os.path.isfile(file_path):
#                     os.remove(file_path)
        
#         logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√©")
#     except Exception as e:
#         logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")
    
#     return JSONResponse({
#         "status": "Flux HLS arr√™t√© et fichiers supprim√©s",
#         "segments_directory": HLS_OUTPUT_DIR
#     })

# @app.get("/api/clean")
# async def clean_files():
#     """Nettoie tous les fichiers HLS (segments et playlist) et le dossier analytics"""
#     try:
#         # Supprimer tous les fichiers .ts et .m3u8
#         for file in os.listdir(HLS_OUTPUT_DIR):
#             file_path = os.path.join(HLS_OUTPUT_DIR, file)
#             if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
#                 os.remove(file_path)
        
#         # Nettoyer le dossier analytics
#         analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
#         if os.path.exists(analytics_dir):
#             for file in os.listdir(analytics_dir):
#                 file_path = os.path.join(analytics_dir, file)
#                 if os.path.isfile(file_path):
#                     os.remove(file_path)
        
#         logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√©")
        
#         return JSONResponse({"status": "Tous les fichiers HLS et analytics ont √©t√© supprim√©s"})
#     except Exception as e:
#         logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")
#         return JSONResponse({
#             "status": "Erreur lors du nettoyage",
#             "error": str(e)
#         }, status_code=500)


# @app.get("/api/verify_cleanup")
# async def verify_cleanup():
#     """V√©rifie que le dossier HLS a √©t√© nettoy√©."""
#     try:
#         # V√©rifier si le dossier existe et est vide
#         if os.path.exists(HLS_OUTPUT_DIR):
#             files = [f for f in os.listdir(HLS_OUTPUT_DIR) 
#                     if os.path.isfile(os.path.join(HLS_OUTPUT_DIR, f))]
#             if files:
#                 return JSONResponse({
#                     "status": "Dossier non vide",
#                     "remaining_files": files,
#                     "should_clean": True
#                 }, status_code=400)
        
#         return JSONResponse({
#             "status": "Dossier propre",
#             "details": "Aucun fichier trouv√© dans le dossier HLS"
#         })
        
#     except Exception as e:
#         logger.error(f"Erreur v√©rification: {str(e)}")
#         return JSONResponse({
#             "status": "Erreur lors de la v√©rification",
#             "error": str(e)
#         }, status_code=500)



# @app.get("/api/status")
# async def get_status():
#     """Retourne le statut actuel avec informations de tracking"""
#     is_active = not restart_event.is_set() and active_rtsp_url is not None
    
#     playlist_exists = os.path.exists(f"{HLS_OUTPUT_DIR}/playlist.m3u8")
    
#     ts_segments = [f for f in os.listdir(HLS_OUTPUT_DIR) if f.endswith('.ts')]
    
#     total_size_bytes = 0
#     for segment in ts_segments:
#         segment_path = os.path.join(HLS_OUTPUT_DIR, segment)
#         total_size_bytes += os.path.getsize(segment_path)
    
#     total_size_mb = total_size_bytes / (1024 * 1024)
    
#     # V√©rifier si les annotations AI sont pr√©sentes dans les segments
#     annotations_in_segments = False
#     if ai_enabled and os.path.exists(f"{HLS_ANALYTICS_DIR}/annotated_frame.npy"):
#         annotations_in_segments = True
    
#     tracking_info = {}
#     if ai_enabled:
#         current_time = time.time()
#         tracked_objects_clean = {}
#         for track_id, obj_info in detection_results["tracked_objects"].items():
#             if current_time - obj_info["last_seen"] < 10.0:
#                 tracked_objects_clean[track_id] = {
#                     "class": obj_info["class"],
#                     "duration": round(current_time - obj_info["first_seen"], 1),
#                     "last_seen": round(current_time - obj_info["last_seen"], 1),
#                     "position": obj_info["position"]
#                 }
        
#         tracking_info["tracked_objects"] = tracked_objects_clean
#         tracking_info["active_tracks"] = len(tracked_objects_clean)
    
#     return JSONResponse({
#         "active": is_active,
#         "current_rtsp_url": active_rtsp_url,
#         "hls_playlist_exists": playlist_exists,
#         "segment_count": len(ts_segments),
#         "segments": sorted(ts_segments)[:10] + ["..."] if len(ts_segments) > 10 else sorted(ts_segments),
#         "ai_enabled": ai_enabled,
#         "ai_annotations_in_segments": annotations_in_segments,  # Nouvelle cl√©
#         "ai_detection": detection_results if ai_enabled else None,
#         "tracking": tracking_info if ai_enabled else None,
#         "disk_usage_mb": round(total_size_mb, 2)
#     })

# @app.get("/api/analytics/image")
# async def get_latest_detection():
#     """Retourne la derni√®re image avec d√©tection"""
#     image_path = f"{HLS_ANALYTICS_DIR}/latest_detection.jpg"
    
#     if os.path.exists(image_path):
#         return FileResponse(image_path)
#     else:
#         raise HTTPException(status_code=404, detail="Image de d√©tection non disponible")

# @app.get("/api/tracking/status")
# async def get_tracking_status():
#     """Retourne l'√©tat d√©taill√© du tracking des objets"""
#     if not ai_enabled:
#         return JSONResponse({
#             "status": "AI d√©sactiv√©e",
#             "tracking_enabled": False
#         })
    
#     # Nettoyer les objets suivis qui n'ont pas √©t√© vus depuis plus de 10 secondes
#     current_time = time.time()
#     tracked_objects_clean = {}
#     for track_id, obj_info in detection_results["tracked_objects"].items():
#         if current_time - obj_info["last_seen"] < 10.0:
#             tracked_objects_clean[track_id] = {
#                 "class": obj_info["class"],
#                 "duration": round(current_time - obj_info["first_seen"], 1),
#                 "last_seen": round(current_time - obj_info["last_seen"], 1),
#                 "position": obj_info["position"]
#             }
    
#     # Analyser les statistiques
#     class_counts = defaultdict(int)
#     for obj_info in tracked_objects_clean.values():
#         class_counts[obj_info["class"]] += 1
    
#     return JSONResponse({
#         "status": "Tracking actif",
#         "tracking_enabled": True,
#         "active_tracks": len(tracked_objects_clean),
#         "class_distribution": dict(class_counts),
#         "tracked_objects": tracked_objects_clean
#     })

# @app.get("/api/cleanup")
# async def cleanup_segments(
#     keep_last: int = Query(10, description="Nombre de segments r√©cents √† conserver (0 pour tout garder)")
# ):
#     """Nettoie les anciens segments tout en pr√©servant les plus r√©cents"""
#     try:
#         ts_segments = sorted([f for f in os.listdir(HLS_OUTPUT_DIR) if f.endswith('.ts')])
        
#         if keep_last > 0 and len(ts_segments) > keep_last:
#             segments_to_delete = ts_segments[:-keep_last]
#             for segment in segments_to_delete:
#                 segment_path = os.path.join(HLS_OUTPUT_DIR, segment)
#                 os.remove(segment_path)
            
#             return JSONResponse({
#                 "status": "Nettoyage effectu√©",
#                 "segments_deleted": len(segments_to_delete),
#                 "segments_kept": min(keep_last, len(ts_segments))
#             })
#         else:
#             return JSONResponse({
#                 "status": "Aucun nettoyage n√©cessaire",
#                 "segment_count": len(ts_segments)
#             })
#     except Exception as e:
#         logger.error(f"Erreur lors du nettoyage des segments: {str(e)}")
#         return JSONResponse({
#             "status": "Erreur lors du nettoyage",
#             "error": str(e)
#         }, status_code=500)


# @app.on_event("shutdown")
# async def shutdown_event():
#     """Actions √† ex√©cuter √† l'arr√™t de l'application"""
#     logger.info("Arr√™t de l'application, nettoyage des fichiers...")
    
#     # Nettoyer tous les fichiers du dossier HLS
#     try:
#         # Supprimer tous les fichiers .ts et .m3u8
#         for file in os.listdir(HLS_OUTPUT_DIR):
#             file_path = os.path.join(HLS_OUTPUT_DIR, file)
#             if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
#                 os.remove(file_path)
        
#         # Nettoyer le dossier analytics
#         analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
#         if os.path.exists(analytics_dir):
#             for file in os.listdir(analytics_dir):
#                 file_path = os.path.join(analytics_dir, file)
#                 if os.path.isfile(file_path):
#                     os.remove(file_path)
        
#         logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√©")
#     except Exception as e:
#         logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")
        
# # Montage des fichiers statiques pour l'acc√®s HLS
# app.mount("/hls", StaticFiles(directory=HLS_OUTPUT_DIR), name="hls")


# @app.on_event("startup")
# async def startup_event():
#     """Actions √† ex√©cuter au d√©marrage"""
#     # Cr√©er les r√©pertoires si n√©cessaire, mais ne pas supprimer les fichiers
#     Path(HLS_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
#     Path(HLS_ANALYTICS_DIR).mkdir(parents=True, exist_ok=True)
#     logger.info("Application d√©marr√©e et pr√™te √† recevoir des connexions")

# if __name__ == '__main__':
#     import uvicorn
#     uvicorn.run(app, host='0.0.0.0', port=HTTP_PORT, log_level="info")









############################# code grok ############################
# import os
# import subprocess
# import threading
# import time
# import cv2
# import numpy as np
# import logging
# from pathlib import Path
# from fastapi import FastAPI, Query, HTTPException
# from fastapi.responses import JSONResponse, FileResponse
# from fastapi.staticfiles import StaticFiles
# from ultralytics import YOLO
# import shutil
# import queue
# from collections import defaultdict
# import signal
# import sys
# import hashlib

# # Configuration du logging
# logging.basicConfig(level=logging.INFO)
# logger = logging.getLogger(__name__)

# app = FastAPI(title="RTSP to HLS Converter with AI Detection and Tracking")

# # Configuration
# HLS_OUTPUT_DIR = "tmp/hls_output"
# HLS_ANALYTICS_DIR = f"{HLS_OUTPUT_DIR}/analytics"
# HTTP_PORT = 8020
# PIPE_PATH = "tmp/ffmpeg_pipe.yuv"

# # S'assurer que les r√©pertoires existent
# Path(HLS_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
# Path(HLS_ANALYTICS_DIR).mkdir(parents=True, exist_ok=True)
# Path(os.path.dirname(PIPE_PATH)).mkdir(parents=True, exist_ok=True)

# # Charger les mod√®les YOLO une seule fois au d√©marrage
# try:
#     yolo_model = YOLO("yolov8n.pt").to('cuda')
#     face_model = YOLO("yolov8n-face.pt").to('cuda')
#     logger.info("Mod√®les YOLO charg√©s avec succ√®s")
# except Exception as e:
#     logger.error(f"Erreur lors du chargement des mod√®les YOLO: {str(e)}")
#     yolo_model = None
#     face_model = None

# # Variables globales
# current_process = None
# detection_queue = queue.Queue(maxsize=5)  # R√©duit pour √©viter l'accumulation
# process_lock = threading.Lock()
# restart_event = threading.Event()
# active_rtsp_url = None
# ai_enabled = True
# detection_results = {
#     "objects": {},
#     "faces": 0,
#     "last_update": None,
#     "tracked_objects": {}
# }

# def signal_handler(sig, frame):
#     """Gestionnaire de signal pour l'arr√™t propre de l'application"""
#     logger.info("Signal d'arr√™t re√ßu, nettoyage en cours...")
#     try:
#         for file in os.listdir(HLS_OUTPUT_DIR):
#             file_path = os.path.join(HLS_OUTPUT_DIR, file)
#             if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
#                 os.remove(file_path)
#         analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
#         if os.path.exists(analytics_dir):
#             for file in os.listdir(analytics_dir):
#                 file_path = os.path.join(analytics_dir, file)
#                 if os.path.isfile(file_path):
#                     os.remove(file_path)
#         logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√©")
#     except Exception as e:
#         logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")
#     sys.exit(0)

# signal.signal(signal.SIGINT, signal_handler)
# signal.signal(signal.SIGTERM, signal_handler)

# rtsp_transports = ["tcp", "udp", "http", "udp_multicast"]

# def draw_boxes_with_tracking(frame, results):
#     """Dessine les bo√Ætes de d√©tection avec IDs de tracking sur l'image"""
#     annotated_frame = frame.copy()
#     if hasattr(results, 'boxes') and results.boxes:
#         for box in results.boxes:
#             x1, y1, x2, y2 = map(int, box.xyxy[0])
#             conf = float(box.conf[0])
#             cls = int(box.cls[0])
#             class_name = results.names[cls]
#             color = (0, 255, 0) if class_name == "person" else (0, 0, 255) if "face" in class_name.lower() else (255, 0, 0)
#             track_id = int(box.id[0]) if hasattr(box, 'id') and box.id is not None else None
#             if track_id:
#                 if track_id not in detection_results["tracked_objects"]:
#                     detection_results["tracked_objects"][track_id] = {
#                         "class": class_name,
#                         "first_seen": time.time(),
#                         "last_seen": time.time(),
#                         "position": (int((x1+x2)/2), int((y1+y2)/2))
#                     }
#                 else:
#                     detection_results["tracked_objects"][track_id]["last_seen"] = time.time()
#                     detection_results["tracked_objects"][track_id]["position"] = (int((x1+x2)/2), int((y1+y2)/2))
#                 label = f"{class_name} #{track_id}: {conf:.2f}"
#             else:
#                 label = f"{class_name}: {conf:.2f}"
#             cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
#             text_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
#             cv2.rectangle(annotated_frame, (x1, y1 - text_size[1] - 10), (x1 + text_size[0], y1), color, -1)
#             cv2.putText(annotated_frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
#     return annotated_frame

# def detection_worker():
#     """Thread d√©di√© √† l'analyse d'images pour ne pas bloquer le flux vid√©o"""
#     global detection_results
#     logger.info("D√©marrage du thread de d√©tection AI")
#     last_annotated_hash = None
#     while not restart_event.is_set():
#         try:
#             if detection_queue.empty():
#                 time.sleep(0.01)
#                 continue
#             frame = detection_queue.get()
#             objects_detected = defaultdict(int)
#             face_count = 0
#             annotated_frame = frame.copy()
#             if yolo_model:
#                 object_results = yolo_model.track(frame, persist=True, tracker="bytetrack.yaml")
#                 for r in object_results:
#                     annotated_frame = draw_boxes_with_tracking(annotated_frame, r)
#                     if r.boxes:
#                         for box in r.boxes:
#                             cls = int(box.cls[0])
#                             class_name = r.names[cls]
#                             objects_detected[class_name] += 1
#             if face_model:
#                 face_results = face_model.track(frame, persist=True, tracker="bytetrack.yaml")
#                 for r in face_results:
#                     annotated_frame = draw_boxes_with_tracking(annotated_frame, r)
#                     if r.boxes:
#                         face_count += len(r.boxes)
#             detection_results["objects"] = dict(objects_detected)
#             detection_results["faces"] = face_count
#             detection_results["last_update"] = time.strftime("%Y-%m-%d %H:%M:%S")
#             current_time = time.time()
#             to_remove = []
#             for track_id, obj_info in detection_results["tracked_objects"].items():
#                 if current_time - obj_info["last_seen"] > 5.0:
#                     to_remove.append(track_id)
#             for track_id in to_remove:
#                 del detection_results["tracked_objects"][track_id]
#             frame_hash = hashlib.md5(annotated_frame.tobytes()).hexdigest()
#             if frame_hash != last_annotated_hash:
#                 with open(f"{HLS_ANALYTICS_DIR}/annotated_frame.npy", 'wb') as f:
#                     np.save(f, annotated_frame)
#                 last_annotated_hash = frame_hash
#         except Exception as e:
#             logger.error(f"Erreur dans le thread de d√©tection: {str(e)}")
#             time.sleep(0.1)


# def update_detection_results(results):
#     """Met √† jour les r√©sultats de d√©tection globaux"""
#     global detection_results
    
#     if not results or len(results) == 0:
#         return
        
#     objects_detected = defaultdict(int)
#     face_count = 0
    
#     for box in results[0].boxes:
#         cls = int(box.cls[0])
#         class_name = results[0].names[cls]
#         objects_detected[class_name] += 1
        
#         if "face" in class_name.lower():
#             face_count += 1
    
#     detection_results.update({
#         "objects": dict(objects_detected),
#         "faces": face_count,
#         "last_update": time.strftime("%Y-%m-%d %H:%M:%S")
#     })

# def rtsp_reader_thread(rtsp_url):
#     """Thread de lecture RTSP optimis√© pour la fluidit√© avec traitement IA en temps r√©el"""
#     global detection_results
    
#     logger.info(f"D√©marrage du thread RTSP optimis√© pour: {rtsp_url}")
    
#     # Configuration basse latence
#     cv2.setNumThreads(2)  # Limiter les threads OpenCV
#     os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;tcp|buffer_size;1024000"
    
#     cap = None
#     ffmpeg_process = None
#     frame_skip_counter = 0
#     last_fps_log = time.time()
#     processed_frames = 0
    
#     while not restart_event.is_set():
#         try:
#             # Initialisation du flux
#             cap = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)
#             cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
#             cap.set(cv2.CAP_PROP_FPS, 30)
            
#             if not cap.isOpened():
#                 raise RuntimeError(f"√âchec d'ouverture du flux RTSP: {rtsp_url}")
                
#             # Configuration FFmpeg basse latence
#             width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#             height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#             fps = cap.get(cv2.CAP_PROP_FPS) or 25.0
            
#             ffmpeg_process = subprocess.Popen([
#                 "ffmpeg",
#                 "-y",
#                 "-loglevel", "error",
#                 "-f", "rawvideo",
#                 "-vcodec", "rawvideo",
#                 "-pix_fmt", "bgr24",
#                 "-s", f"{width}x{height}",
#                 "-r", str(fps),
#                 "-i", "-",
#                 "-c:v", "libx264",
#                 "-preset", "ultrafast",
#                 "-tune", "zerolatency",
#                 "-g", "15",
#                 "-keyint_min", "15",
#                 "-pix_fmt", "yuv420p",
#                 "-f", "hls",
#                 "-hls_time", "0.5",
#                 "-hls_flags", "independent_segments+delete_segments",
#                 "-hls_list_size", "3",
#                 f"{HLS_OUTPUT_DIR}/playlist.m3u8"
#             ], stdin=subprocess.PIPE)
            
#             # Boucle principale de traitement
#             while not restart_event.is_set() and cap.isOpened():
#                 start_time = time.time()
                
#                 # Lecture frame
#                 ret, frame = cap.read()
#                 if not ret:
#                     frame_skip_counter += 1
#                     if frame_skip_counter > 30:
#                         logger.warning("Trop de frames manqu√©es, reconnexion...")
#                         break
#                     time.sleep(0.01)
#                     continue
                
#                 frame_skip_counter = 0
#                 processed_frames += 1
                
#                 # Traitement temps-r√©el
#                 display_frame = frame.copy()
#                 if ai_enabled:
#                     try:
#                         # D√©tection IA avec timeout
#                         results = yolo_model.track(
#                             frame, 
#                             persist=True, 
#                             verbose=False,
#                             imgsz=640,  # R√©duction r√©solution pour YOLO
#                             half=True    # Activation float16 si GPU
#                         )
                        
#                         # Mise √† jour des r√©sultats
#                         update_detection_results(results)
                        
#                         # Annotation
#                         display_frame = draw_boxes_with_tracking(frame, results[0])
#                     except Exception as e:
#                         logger.error(f"Erreur IA: {str(e)}")
                
#                 # Encodage HLS
#                 try:
#                     ffmpeg_process.stdin.write(
#                         display_frame.tobytes()
#                     )
#                 except BrokenPipeError:
#                     logger.error("FFmpeg pipe broken, red√©marrage...")
#                     break
                
#                 # Log des performances
#                 if time.time() - last_fps_log > 5.0:
#                     current_fps = processed_frames / (time.time() - last_fps_log)
#                     logger.info(f"FPS: {current_fps:.1f} | Latence: {(time.time() - start_time)*1000:.1f}ms")
#                     processed_frames = 0
#                     last_fps_log = time.time()
                
#         except Exception as e:
#             logger.error(f"Erreur dans le thread RTSP: {str(e)}")
#             time.sleep(2)
            
#         finally:
#             # Nettoyage
#             if cap:
#                 cap.release()
#             if ffmpeg_process and ffmpeg_process.poll() is None:
#                 ffmpeg_process.stdin.close()
#                 ffmpeg_process.terminate()
#                 try:
#                     ffmpeg_process.wait(timeout=5)
#                 except subprocess.TimeoutExpired:
#                     ffmpeg_process.kill()
            
#             if not restart_event.is_set():
#                 time.sleep(1)

# def configure_ffmpeg(width, height, fps):
#     """Configure FFmpeg avec des param√®tres optimis√©s pour la fluidit√©"""
#     try:
#         ffmpeg_cmd = [
#             "ffmpeg",
#             "-loglevel", "error",
#             "-threads", "4",  # Utiliser plusieurs threads
#             "-fflags", "nobuffer",  # R√©duire le buffering
#             "-flags", "low_delay",
#             "-strict", "experimental",
#             "-f", "image2pipe",
#             "-framerate", str(fps),
#             "-i", "-",
#             "-c:v", "libx264",
#             "-preset", "ultrafast",
#             "-tune", "zerolatency",
#             "-x264-params", "keyint=15:no-scenecut=1",  # GOP plus court
#             "-bf", "0",  # Pas de B-frames
#             "-pix_fmt", "yuv420p",
#             "-f", "hls",
#             "-hls_time", "0.5",  # Segments plus courts
#             "-hls_flags", "independent_segments+delete_segments",
#             "-hls_list_size", "3",  # Playlist plus courte
#             f"{HLS_OUTPUT_DIR}/playlist.m3u8"
#         ]
#         logger.info(f"Configuration FFmpeg: {' '.join(ffmpeg_cmd)}")
#         return subprocess.Popen(
#             ffmpeg_cmd,
#             stdin=subprocess.PIPE,
#             stdout=subprocess.PIPE,
#             stderr=subprocess.PIPE,
#             bufsize=10**8
#         )
#     except Exception as e:
#         logger.error(f"Erreur configuration FFmpeg: {str(e)}")
#         return None

# def start_hls_conversion_with_detection(rtsp_url):
#     """D√©marre la conversion RTSP vers HLS avec d√©tection AI int√©gr√©e"""
#     global current_process, active_rtsp_url
#     prepare_hls_directory()
#     threading.Thread(
#         target=rtsp_reader_thread,
#         args=(rtsp_url,),
#         daemon=True
#     ).start()
#     active_rtsp_url = rtsp_url

# def prepare_hls_directory():
#     """Pr√©pare le r√©pertoire HLS sans supprimer les fichiers existants"""
#     try:
#         Path(HLS_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
#         Path(HLS_ANALYTICS_DIR).mkdir(parents=True, exist_ok=True)
#         playlist_path = os.path.join(HLS_OUTPUT_DIR, "playlist.m3u8")
#         if os.path.exists(playlist_path):
#             timestamp = time.strftime("%Y%m%d-%H%M%S")
#             archive_path = os.path.join(HLS_OUTPUT_DIR, f"playlist_archive_{timestamp}.m3u8")
#             shutil.copy2(playlist_path, archive_path)
#             logger.info(f"Playlist existante archiv√©e sous: {archive_path}")
#         logger.info("R√©pertoire HLS pr√©par√©")
#     except Exception as e:
#         logger.error(f"Erreur lors de la pr√©paration du r√©pertoire HLS: {str(e)}")

# @app.get("/api/start")
# async def start_processing(
#     rtsp_url: str = Query(..., description="URL RTSP √† convertir en HLS"),
#     enable_ai: bool = Query(True, description="Activer la d√©tection AI")
# ):
#     """D√©marre ou met √† jour la conversion RTSP vers HLS avec d√©tection AI"""
#     global restart_event, ai_enabled
#     if not rtsp_url.startswith("rtsp://"):
#         raise HTTPException(status_code=400, detail="URL RTSP invalide")
#     ai_enabled = enable_ai
#     restart_event.set()
#     time.sleep(1)
#     restart_event.clear()
#     try:
#         for file in os.listdir(HLS_OUTPUT_DIR):
#             file_path = os.path.join(HLS_OUTPUT_DIR, file)
#             if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
#                 os.remove(file_path)
#         analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
#         if os.path.exists(analytics_dir):
#             for file in os.listdir(analytics_dir):
#                 file_path = os.path.join(analytics_dir, file)
#                 if os.path.isfile(file_path):
#                     os.remove(file_path)
#         logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√© avant d√©marrage")
#     except Exception as e:
#         logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")
#     start_hls_conversion_with_detection(rtsp_url)
#     return JSONResponse({
#         "status": "Conversion avec AI int√©gr√©e d√©marr√©e",
#         "rtsp_url": rtsp_url,
#         "hls_url": f"http://localhost:{HTTP_PORT}/hls/playlist.m3u8",
#         "ai_enabled": ai_enabled
#     })

# @app.get("/api/stop")
# async def stop_processing():
#     """Arr√™te le processus de conversion et nettoie tous les fichiers"""
#     global restart_event, active_rtsp_url
#     restart_event.set()
#     time.sleep(1)
#     active_rtsp_url = None
#     try:
#         for file in os.listdir(HLS_OUTPUT_DIR):
#             file_path = os.path.join(HLS_OUTPUT_DIR, file)
#             if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
#                 os.remove(file_path)
#         analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
#         if os.path.exists(analytics_dir):
#             for file in os.listdir(analytics_dir):
#                 file_path = os.path.join(analytics_dir, file)
#                 if os.path.isfile(file_path):
#                     os.remove(file_path)
#         logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√©")
#     except Exception as e:
#         logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")
#     return JSONResponse({
#         "status": "Flux HLS arr√™t√© et fichiers supprim√©s",
#         "segments_directory": HLS_OUTPUT_DIR
#     })

# @app.get("/api/clean")
# async def clean_files():
#     """Nettoie tous les fichiers HLS (segments et playlist) et le dossier analytics"""
#     try:
#         for file in os.listdir(HLS_OUTPUT_DIR):
#             file_path = os.path.join(HLS_OUTPUT_DIR, file)
#             if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
#                 os.remove(file_path)
#         analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
#         if os.path.exists(analytics_dir):
#             for file in os.listdir(analytics_dir):
#                 file_path = os.path.join(analytics_dir, file)
#                 if os.path.isfile(file_path):
#                     os.remove(file_path)
#         logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√©")
#         return JSONResponse({"status": "Tous les fichiers HLS et analytics ont √©t√© supprim√©s"})
#     except Exception as e:
#         logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")
#         return JSONResponse({
#             "status": "Erreur lors du nettoyage",
#             "error": str(e)
#         }, status_code=500)

# @app.get("/api/verify_cleanup")
# async def verify_cleanup():
#     """V√©rifie que le dossier HLS a √©t√© nettoy√©."""
#     try:
#         if os.path.exists(HLS_OUTPUT_DIR):
#             files = [f for f in os.listdir(HLS_OUTPUT_DIR) 
#                     if os.path.isfile(os.path.join(HLS_OUTPUT_DIR, f))]
#             if files:
#                 return JSONResponse({
#                     "status": "Dossier non vide",
#                     "remaining_files": files,
#                     "should_clean": True
#                 }, status_code=400)
#         return JSONResponse({
#             "status": "Dossier propre",
#             "details": "Aucun fichier trouv√© dans le dossier HLS"
#         })
#     except Exception as e:
#         logger.error(f"Erreur v√©rification: {str(e)}")
#         return JSONResponse({
#             "status": "Erreur lors de la v√©rification",
#             "error": str(e)
#         }, status_code=500)

# @app.get("/api/status")
# async def get_status():
#     """Retourne le statut actuel avec informations de tracking"""
#     is_active = not restart_event.is_set() and active_rtsp_url is not None
#     playlist_exists = os.path.exists(f"{HLS_OUTPUT_DIR}/playlist.m3u8")
#     ts_segments = [f for f in os.listdir(HLS_OUTPUT_DIR) if f.endswith('.ts')]
#     total_size_bytes = 0
#     for segment in ts_segments:
#         segment_path = os.path.join(HLS_OUTPUT_DIR, segment)
#         total_size_bytes += os.path.getsize(segment_path)
#     total_size_mb = total_size_bytes / (1024 * 1024)
#     annotations_in_segments = False
#     if ai_enabled and os.path.exists(f"{HLS_ANALYTICS_DIR}/annotated_frame.npy"):
#         annotations_in_segments = True
#     tracking_info = {}
#     if ai_enabled:
#         current_time = time.time()
#         tracked_objects_clean = {}
#         for track_id, obj_info in detection_results["tracked_objects"].items():
#             if current_time - obj_info["last_seen"] < 10.0:
#                 tracked_objects_clean[track_id] = {
#                     "class": obj_info["class"],
#                     "duration": round(current_time - obj_info["first_seen"], 1),
#                     "last_seen": round(current_time - obj_info["last_seen"], 1),
#                     "position": obj_info["position"]
#                 }
#         tracking_info["tracked_objects"] = tracked_objects_clean
#         tracking_info["active_tracks"] = len(tracked_objects_clean)
#     return JSONResponse({
#         "active": is_active,
#         "current_rtsp_url": active_rtsp_url,
#         "hls_playlist_exists": playlist_exists,
#         "segment_count": len(ts_segments),
#         "segments": sorted(ts_segments)[:10] + ["..."] if len(ts_segments) > 10 else sorted(ts_segments),
#         "ai_enabled": ai_enabled,
#         "ai_annotations_in_segments": annotations_in_segments,
#         "ai_detection": detection_results if ai_enabled else None,
#         "tracking": tracking_info if ai_enabled else None,
#         "disk_usage_mb": round(total_size_mb, 2)
#     })

# @app.get("/api/analytics/image")
# async def get_latest_detection():
#     """Retourne la derni√®re image avec d√©tection"""
#     image_path = f"{HLS_ANALYTICS_DIR}/latest_detection.jpg"
#     if os.path.exists(image_path):
#         return FileResponse(image_path)
#     else:
#         raise HTTPException(status_code=404, detail="Image de d√©tection non disponible")

# @app.get("/api/tracking/status")
# async def get_tracking_status():
#     """Retourne l'√©tat d√©taill√© du tracking des objets"""
#     if not ai_enabled:
#         return JSONResponse({
#             "status": "AI d√©sactiv√©e",
#             "tracking_enabled": False
#         })
#     current_time = time.time()
#     tracked_objects_clean = {}
#     for track_id, obj_info in detection_results["tracked_objects"].items():
#         if current_time - obj_info["last_seen"] < 10.0:
#             tracked_objects_clean[track_id] = {
#                 "class": obj_info["class"],
#                 "duration": round(current_time - obj_info["first_seen"], 1),
#                 "last_seen": round(current_time - obj_info["last_seen"], 1),
#                 "position": obj_info["position"]
#             }
#     class_counts = defaultdict(int)
#     for obj_info in tracked_objects_clean.values():
#         class_counts[obj_info["class"]] += 1
#     return JSONResponse({
#         "status": "Tracking actif",
#         "tracking_enabled": True,
#         "active_tracks": len(tracked_objects_clean),
#         "class_distribution": dict(class_counts),
#         "tracked_objects": tracked_objects_clean
#     })

# @app.get("/api/cleanup")
# async def cleanup_segments(
#     keep_last: int = Query(10, description="Nombre de segments r√©cents √† conserver (0 pour tout garder)")
# ):
#     """Nettoie les anciens segments tout en pr√©servant les plus r√©cents"""
#     try:
#         ts_segments = sorted([f for f in os.listdir(HLS_OUTPUT_DIR) if f.endswith('.ts')])
#         if keep_last > 0 and len(ts_segments) > keep_last:
#             segments_to_delete = ts_segments[:-keep_last]
#             for segment in segments_to_delete:
#                 segment_path = os.path.join(HLS_OUTPUT_DIR, segment)
#                 os.remove(segment_path)
#             return JSONResponse({
#                 "status": "Nettoyage effectu√©",
#                 "segments_deleted": len(segments_to_delete),
#                 "segments_kept": min(keep_last, len(ts_segments))
#             })
#         else:
#             return JSONResponse({
#                 "status": "Aucun nettoyage n√©cessaire",
#                 "segment_count": len(ts_segments)
#             })
#     except Exception as e:
#         logger.error(f"Erreur lors du nettoyage des segments: {str(e)}")
#         return JSONResponse({
#             "status": "Erreur lors du nettoyage",
#             "error": str(e)
#         }, status_code=500)

# @app.on_event("shutdown")
# async def shutdown_event():
#     """Actions √† ex√©cuter √† l'arr√™t de l'application"""
#     logger.info("Arr√™t de l'application, nettoyage des fichiers...")
#     try:
#         for file in os.listdir(HLS_OUTPUT_DIR):
#             file_path = os.path.join(HLS_OUTPUT_DIR, file)
#             if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
#                 os.remove(file_path)
#         analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
#         if os.path.exists(analytics_dir):
#             for file in os.listdir(analytics_dir):
#                 file_path = os.path.join(analytics_dir, file)
#                 if os.path.isfile(file_path):
#                     os.remove(file_path)
#         logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√©")
#     except Exception as e:
#         logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")

# app.mount("/hls", StaticFiles(directory=HLS_OUTPUT_DIR), name="hls")

# @app.on_event("startup")
# async def startup_event():
#     """Actions √† ex√©cuter au d√©marrage"""
#     Path(HLS_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
#     Path(HLS_ANALYTICS_DIR).mkdir(parents=True, exist_ok=True)
#     logger.info("Application d√©marr√©e et pr√™te √† recevoir des connexions")

# if __name__ == '__main__':
#     import uvicorn
#     uvicorn.run(app, host='0.0.0.0', port=HTTP_PORT, log_level="info")




################################# test 2 #####################################################

import os
import subprocess
import threading
import time
import cv2
import numpy as np
import logging
from pathlib import Path
from fastapi import FastAPI, Query, HTTPException
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from ultralytics import YOLO
import shutil
import queue
from collections import defaultdict
import signal
import sys
import hashlib

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="RTSP to HLS Converter with AI Detection and Tracking")

# Configuration
HLS_OUTPUT_DIR = "tmp/hls_output"
HLS_ANALYTICS_DIR = f"{HLS_OUTPUT_DIR}/analytics"
HTTP_PORT = 8020
PIPE_PATH = "tmp/ffmpeg_pipe.yuv"

# S'assurer que les r√©pertoires existent
Path(HLS_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
Path(HLS_ANALYTICS_DIR).mkdir(parents=True, exist_ok=True)
Path(os.path.dirname(PIPE_PATH)).mkdir(parents=True, exist_ok=True)

# Charger les mod√®les YOLO une seule fois au d√©marrage
try:
    yolo_model = YOLO("yolov8n.pt").to('cuda')
    face_model = YOLO("yolov8n-face.pt").to('cuda')
    logger.info("Mod√®les YOLO charg√©s avec succ√®s")
except Exception as e:
    logger.error(f"Erreur lors du chargement des mod√®les YOLO: {str(e)}")
    yolo_model = None
    face_model = None

# Variables globales
current_process = None
detection_queue = queue.Queue(maxsize=5)  # R√©duit pour √©viter l'accumulation
process_lock = threading.Lock()
restart_event = threading.Event()
active_rtsp_url = None
ai_enabled = True
detection_results = {
    "objects": {},
    "faces": 0,
    "last_update": None,
    "tracked_objects": {}
}

def signal_handler(sig, frame):
    """Gestionnaire de signal pour l'arr√™t propre de l'application"""
    logger.info("Signal d'arr√™t re√ßu, nettoyage en cours...")
    try:
        for file in os.listdir(HLS_OUTPUT_DIR):
            file_path = os.path.join(HLS_OUTPUT_DIR, file)
            if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
                os.remove(file_path)
        analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
        if os.path.exists(analytics_dir):
            for file in os.listdir(analytics_dir):
                file_path = os.path.join(analytics_dir, file)
                if os.path.isfile(file_path):
                    os.remove(file_path)
        logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√©")
    except Exception as e:
        logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

rtsp_transports = ["tcp", "udp", "http", "udp_multicast"]

def draw_boxes_with_tracking(frame, results):
    """Dessine les bo√Ætes de d√©tection avec IDs de tracking sur l'image"""
    annotated_frame = frame.copy()
    if hasattr(results, 'boxes') and results.boxes:
        for box in results.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            conf = float(box.conf[0])
            cls = int(box.cls[0])
            class_name = results.names[cls]
            color = (0, 255, 0) if class_name == "person" else (0, 0, 255) if "face" in class_name.lower() else (255, 0, 0)
            track_id = int(box.id[0]) if hasattr(box, 'id') and box.id is not None else None
            if track_id:
                if track_id not in detection_results["tracked_objects"]:
                    detection_results["tracked_objects"][track_id] = {
                        "class": class_name,
                        "first_seen": time.time(),
                        "last_seen": time.time(),
                        "position": (int((x1+x2)/2), int((y1+y2)/2))
                    }
                else:
                    detection_results["tracked_objects"][track_id]["last_seen"] = time.time()
                    detection_results["tracked_objects"][track_id]["position"] = (int((x1+x2)/2), int((y1+y2)/2))
                label = f"{class_name} #{track_id}: {conf:.2f}"
            else:
                label = f"{class_name}: {conf:.2f}"
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
            text_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
            cv2.rectangle(annotated_frame, (x1, y1 - text_size[1] - 10), (x1 + text_size[0], y1), color, -1)
            cv2.putText(annotated_frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    return annotated_frame

def detection_worker():
    """Thread d√©di√© √† l'analyse d'images pour ne pas bloquer le flux vid√©o"""
    global detection_results
    logger.info("D√©marrage du thread de d√©tection AI")
    last_annotated_hash = None
    while not restart_event.is_set():
        try:
            if detection_queue.empty():
                time.sleep(0.01)
                continue
            frame = detection_queue.get()
            objects_detected = defaultdict(int)
            face_count = 0
            annotated_frame = frame.copy()
            if yolo_model:
                object_results = yolo_model.track(frame, persist=True, tracker="bytetrack.yaml")
                for r in object_results:
                    annotated_frame = draw_boxes_with_tracking(annotated_frame, r)
                    if r.boxes:
                        for box in r.boxes:
                            cls = int(box.cls[0])
                            class_name = r.names[cls]
                            objects_detected[class_name] += 1
            if face_model:
                face_results = face_model.track(frame, persist=True, tracker="bytetrack.yaml")
                for r in face_results:
                    annotated_frame = draw_boxes_with_tracking(annotated_frame, r)
                    if r.boxes:
                        face_count += len(r.boxes)
            detection_results["objects"] = dict(objects_detected)
            detection_results["faces"] = face_count
            detection_results["last_update"] = time.strftime("%Y-%m-%d %H:%M:%S")
            current_time = time.time()
            to_remove = []
            for track_id, obj_info in detection_results["tracked_objects"].items():
                if current_time - obj_info["last_seen"] > 5.0:
                    to_remove.append(track_id)
            for track_id in to_remove:
                del detection_results["tracked_objects"][track_id]
            frame_hash = hashlib.md5(annotated_frame.tobytes()).hexdigest()
            if frame_hash != last_annotated_hash:
                with open(f"{HLS_ANALYTICS_DIR}/annotated_frame.npy", 'wb') as f:
                    np.save(f, annotated_frame)
                last_annotated_hash = frame_hash
        except Exception as e:
            logger.error(f"Erreur dans le thread de d√©tection: {str(e)}")
            time.sleep(0.1)


def update_detection_results(results):
    """Met √† jour les r√©sultats de d√©tection globaux"""
    global detection_results
    
    if not results or len(results) == 0:
        return
        
    objects_detected = defaultdict(int)
    face_count = 0
    
    for box in results[0].boxes:
        cls = int(box.cls[0])
        class_name = results[0].names[cls]
        objects_detected[class_name] += 1
        
        if "face" in class_name.lower():
            face_count += 1
    
    detection_results.update({
        "objects": dict(objects_detected),
        "faces": face_count,
        "last_update": time.strftime("%Y-%m-%d %H:%M:%S")
    })

def rtsp_reader_thread(rtsp_url):
    """Thread de lecture RTSP avec gestion correcte de la num√©rotation des segments"""
    global detection_results
    
    cv2.setNumThreads(2)
    os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;tcp|buffer_size;1024000"
    
    cap = None
    ffmpeg_process = None
    frame_skip_counter = 0
    last_fps_log = time.time()
    processed_frames = 0
    
    # Nettoyer le r√©pertoire avant de commencer pour garantir une num√©rotation propre
    prepare_hls_directory()
    
    while not restart_event.is_set():
        try:
            cap = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            cap.set(cv2.CAP_PROP_FPS, 30)
            
            if not cap.isOpened():
                raise RuntimeError(f"√âchec d'ouverture du flux RTSP: {rtsp_url}")
                
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS) or 25.0
            
            # En cas de red√©marrage, nettoyer √† nouveau pour garantir la propret√© de la num√©rotation
            if ffmpeg_process is not None:
                prepare_hls_directory()
            
            ffmpeg_process = subprocess.Popen(
                configure_ffmpeg(width, height, fps),
                stdin=subprocess.PIPE,
                bufsize=10**8
            )
            
            # Boucle principale optimis√©e
            while not restart_event.is_set() and cap.isOpened():
                start_time = time.time()
                
                # Lecture frame avec timeout
                ret, frame = cap.read()
                if not ret:
                    frame_skip_counter += 1
                    if frame_skip_counter > 30:
                        logger.warning("Trop de frames manqu√©es, reconnexion...")
                        break
                    time.sleep(0.01)
                    continue
                
                frame_skip_counter = 0
                processed_frames += 1
                
                # Traitement temps-r√©el avec priorit√© fluidit√©
                display_frame = frame.copy()
                if ai_enabled and processed_frames % 2 == 0:  # Traiter 1 frame sur 2
                    try:
                        # D√©tection IA l√©g√®re
                        results = yolo_model.track(
                            frame, 
                            persist=True, 
                            verbose=False,
                            imgsz=320,  # R√©solution r√©duite
                            half=True    # float16 si GPU
                        )
                        
                        update_detection_results(results)
                        display_frame = draw_boxes_with_tracking(frame, results[0])
                    except Exception as e:
                        logger.error(f"Erreur IA: {str(e)}")
                
                # Envoi √† FFmpeg
                try:
                    ffmpeg_process.stdin.write(display_frame.tobytes())
                except BrokenPipeError:
                    logger.error("FFmpeg pipe broken, red√©marrage...")
                    break
                
                # Log des performances
                if time.time() - last_fps_log > 5.0:
                    current_fps = processed_frames / (time.time() - last_fps_log)
                    logger.info(f"FPS: {current_fps:.1f} | Latence: {(time.time() - start_time)*1000:.1f}ms")
                    processed_frames = 0
                    last_fps_log = time.time()
                
        except Exception as e:
            logger.error(f"Erreur dans le thread RTSP: {str(e)}")
            time.sleep(2)
            
        finally:
            # Nettoyage
            if cap:
                cap.release()
            if ffmpeg_process:
                ffmpeg_process.stdin.close()
                ffmpeg_process.terminate()
            
            if not restart_event.is_set():
                time.sleep(1)

def configure_ffmpeg(width, height, fps):
    """Configuration ultra-optimis√©e de FFmpeg pour faible latence avec num√©rotation s√©quentielle garantie"""
    return [
        "ffmpeg",
        "-loglevel", "error",
        "-threads", "4",
        "-fflags", "nobuffer",
        "-flags", "low_delay",
        "-strict", "experimental",
        "-f", "rawvideo",
        "-vcodec", "rawvideo",
        "-pix_fmt", "bgr24",
        "-s", f"{width}x{height}",
        "-r", str(fps),
        "-i", "-",
        "-c:v", "libx264",
        "-preset", "ultrafast",
        "-tune", "zerolatency",
        "-x264-params", "keyint=15:no-scenecut=1",
        "-bf", "0",
        "-pix_fmt", "yuv420p",
        "-f", "hls",
        "-hls_time", "0.5",
        "-hls_flags", "independent_segments+append_list",  # Ajout de append_list
        "-hls_list_size", "0",
        "-hls_segment_filename", f"{HLS_OUTPUT_DIR}/segment%d.ts",  # Format strict pour les segments
        "-hls_segment_type", "mpegts",  # Type explicite
        "-start_number", "1",  # Commencer la num√©rotation √† 1 de fa√ßon explicite
        "-hls_allow_cache", "0",  # D√©sactiver le cache pour √©viter les probl√®mes de num√©rotation
        f"{HLS_OUTPUT_DIR}/playlist.m3u8"
    ]

def start_hls_conversion_with_detection(rtsp_url):
    """D√©marre la conversion RTSP vers HLS avec d√©tection AI int√©gr√©e"""
    global current_process, active_rtsp_url
    prepare_hls_directory()
    threading.Thread(
        target=rtsp_reader_thread,
        args=(rtsp_url,),
        daemon=True
    ).start()
    active_rtsp_url = rtsp_url

def prepare_hls_directory():
    """Pr√©pare le r√©pertoire HLS en supprimant les segments existants"""
    try:
        Path(HLS_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
        Path(HLS_ANALYTICS_DIR).mkdir(parents=True, exist_ok=True)
        
        # Supprimer tous les segments et playlists existants
        for file in os.listdir(HLS_OUTPUT_DIR):
            file_path = os.path.join(HLS_OUTPUT_DIR, file)
            if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
                os.remove(file_path)
        
        logger.info("R√©pertoire HLS nettoy√© et pr√©par√© pour une nouvelle session")
    except Exception as e:
        logger.error(f"Erreur lors de la pr√©paration du r√©pertoire HLS: {str(e)}")

@app.get("/api/start")
async def start_processing(
    rtsp_url: str = Query(..., description="URL RTSP √† convertir en HLS"),
    enable_ai: bool = Query(True, description="Activer la d√©tection AI")
):
    """D√©marre ou met √† jour la conversion RTSP vers HLS avec d√©tection AI"""
    global restart_event, ai_enabled
    if not rtsp_url.startswith("rtsp://"):
        raise HTTPException(status_code=400, detail="URL RTSP invalide")
    ai_enabled = enable_ai
    restart_event.set()
    time.sleep(1)
    restart_event.clear()
    try:
        for file in os.listdir(HLS_OUTPUT_DIR):
            file_path = os.path.join(HLS_OUTPUT_DIR, file)
            if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
                os.remove(file_path)
        analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
        if os.path.exists(analytics_dir):
            for file in os.listdir(analytics_dir):
                file_path = os.path.join(analytics_dir, file)
                if os.path.isfile(file_path):
                    os.remove(file_path)
        logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√© avant d√©marrage")
    except Exception as e:
        logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")
    start_hls_conversion_with_detection(rtsp_url)
    return JSONResponse({
        "status": "Conversion avec AI int√©gr√©e d√©marr√©e",
        "rtsp_url": rtsp_url,
        "hls_url": f"http://localhost:{HTTP_PORT}/hls/playlist.m3u8",
        "ai_enabled": ai_enabled
    })

@app.get("/api/stop")
async def stop_processing():
    """Arr√™te le processus de conversion et nettoie tous les fichiers"""
    global restart_event, active_rtsp_url
    restart_event.set()
    time.sleep(1)
    active_rtsp_url = None
    try:
        for file in os.listdir(HLS_OUTPUT_DIR):
            file_path = os.path.join(HLS_OUTPUT_DIR, file)
            if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
                os.remove(file_path)
        analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
        if os.path.exists(analytics_dir):
            for file in os.listdir(analytics_dir):
                file_path = os.path.join(analytics_dir, file)
                if os.path.isfile(file_path):
                    os.remove(file_path)
        logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√©")
    except Exception as e:
        logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")
    return JSONResponse({
        "status": "Flux HLS arr√™t√© et fichiers supprim√©s",
        "segments_directory": HLS_OUTPUT_DIR
    })

@app.get("/api/clean")
async def clean_files():
    """Nettoie tous les fichiers HLS (segments et playlist) et le dossier analytics"""
    try:
        for file in os.listdir(HLS_OUTPUT_DIR):
            file_path = os.path.join(HLS_OUTPUT_DIR, file)
            if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
                os.remove(file_path)
        analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
        if os.path.exists(analytics_dir):
            for file in os.listdir(analytics_dir):
                file_path = os.path.join(analytics_dir, file)
                if os.path.isfile(file_path):
                    os.remove(file_path)
        logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√©")
        return JSONResponse({"status": "Tous les fichiers HLS et analytics ont √©t√© supprim√©s"})
    except Exception as e:
        logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")
        return JSONResponse({
            "status": "Erreur lors du nettoyage",
            "error": str(e)
        }, status_code=500)

@app.get("/api/verify_cleanup")
async def verify_cleanup():
    """V√©rifie que le dossier HLS a √©t√© nettoy√©."""
    try:
        if os.path.exists(HLS_OUTPUT_DIR):
            files = [f for f in os.listdir(HLS_OUTPUT_DIR) 
                    if os.path.isfile(os.path.join(HLS_OUTPUT_DIR, f))]
            if files:
                return JSONResponse({
                    "status": "Dossier non vide",
                    "remaining_files": files,
                    "should_clean": True
                }, status_code=400)
        return JSONResponse({
            "status": "Dossier propre",
            "details": "Aucun fichier trouv√© dans le dossier HLS"
        })
    except Exception as e:
        logger.error(f"Erreur v√©rification: {str(e)}")
        return JSONResponse({
            "status": "Erreur lors de la v√©rification",
            "error": str(e)
        }, status_code=500)

@app.get("/api/status")
async def get_status():
    """Retourne le statut actuel avec informations de tracking"""
    is_active = not restart_event.is_set() and active_rtsp_url is not None
    playlist_exists = os.path.exists(f"{HLS_OUTPUT_DIR}/playlist.m3u8")
    ts_segments = [f for f in os.listdir(HLS_OUTPUT_DIR) if f.endswith('.ts')]
    total_size_bytes = 0
    for segment in ts_segments:
        segment_path = os.path.join(HLS_OUTPUT_DIR, segment)
        total_size_bytes += os.path.getsize(segment_path)
    total_size_mb = total_size_bytes / (1024 * 1024)
    annotations_in_segments = False
    if ai_enabled and os.path.exists(f"{HLS_ANALYTICS_DIR}/annotated_frame.npy"):
        annotations_in_segments = True
    tracking_info = {}
    if ai_enabled:
        current_time = time.time()
        tracked_objects_clean = {}
        for track_id, obj_info in detection_results["tracked_objects"].items():
            if current_time - obj_info["last_seen"] < 10.0:
                tracked_objects_clean[track_id] = {
                    "class": obj_info["class"],
                    "duration": round(current_time - obj_info["first_seen"], 1),
                    "last_seen": round(current_time - obj_info["last_seen"], 1),
                    "position": obj_info["position"]
                }
        tracking_info["tracked_objects"] = tracked_objects_clean
        tracking_info["active_tracks"] = len(tracked_objects_clean)
    return JSONResponse({
        "active": is_active,
        "current_rtsp_url": active_rtsp_url,
        "hls_playlist_exists": playlist_exists,
        "segment_count": len(ts_segments),
        "segments": sorted(ts_segments)[:10] + ["..."] if len(ts_segments) > 10 else sorted(ts_segments),
        "ai_enabled": ai_enabled,
        "ai_annotations_in_segments": annotations_in_segments,
        "ai_detection": detection_results if ai_enabled else None,
        "tracking": tracking_info if ai_enabled else None,
        "disk_usage_mb": round(total_size_mb, 2)
    })

@app.get("/api/analytics/image")
async def get_latest_detection():
    """Retourne la derni√®re image avec d√©tection"""
    image_path = f"{HLS_ANALYTICS_DIR}/latest_detection.jpg"
    if os.path.exists(image_path):
        return FileResponse(image_path)
    else:
        raise HTTPException(status_code=404, detail="Image de d√©tection non disponible")

@app.get("/api/tracking/status")
async def get_tracking_status():
    """Retourne l'√©tat d√©taill√© du tracking des objets"""
    if not ai_enabled:
        return JSONResponse({
            "status": "AI d√©sactiv√©e",
            "tracking_enabled": False
        })
    current_time = time.time()
    tracked_objects_clean = {}
    for track_id, obj_info in detection_results["tracked_objects"].items():
        if current_time - obj_info["last_seen"] < 10.0:
            tracked_objects_clean[track_id] = {
                "class": obj_info["class"],
                "duration": round(current_time - obj_info["first_seen"], 1),
                "last_seen": round(current_time - obj_info["last_seen"], 1),
                "position": obj_info["position"]
            }
    class_counts = defaultdict(int)
    for obj_info in tracked_objects_clean.values():
        class_counts[obj_info["class"]] += 1
    return JSONResponse({
        "status": "Tracking actif",
        "tracking_enabled": True,
        "active_tracks": len(tracked_objects_clean),
        "class_distribution": dict(class_counts),
        "tracked_objects": tracked_objects_clean
    })

@app.get("/api/cleanup")
async def cleanup_segments(
    keep_last: int = Query(10, description="Nombre de segments r√©cents √† conserver (0 pour tout garder)")
):
    """Nettoie les anciens segments tout en pr√©servant les plus r√©cents"""
    try:
        ts_segments = sorted([f for f in os.listdir(HLS_OUTPUT_DIR) if f.endswith('.ts')])
        if keep_last > 0 and len(ts_segments) > keep_last:
            segments_to_delete = ts_segments[:-keep_last]
            for segment in segments_to_delete:
                segment_path = os.path.join(HLS_OUTPUT_DIR, segment)
                os.remove(segment_path)
            return JSONResponse({
                "status": "Nettoyage effectu√©",
                "segments_deleted": len(segments_to_delete),
                "segments_kept": min(keep_last, len(ts_segments))
            })
        else:
            return JSONResponse({
                "status": "Aucun nettoyage n√©cessaire",
                "segment_count": len(ts_segments)
            })
    except Exception as e:
        logger.error(f"Erreur lors du nettoyage des segments: {str(e)}")
        return JSONResponse({
            "status": "Erreur lors du nettoyage",
            "error": str(e)
        }, status_code=500)

@app.on_event("shutdown")
async def shutdown_event():
    """Actions √† ex√©cuter √† l'arr√™t de l'application"""
    logger.info("Arr√™t de l'application, nettoyage des fichiers...")
    try:
        for file in os.listdir(HLS_OUTPUT_DIR):
            file_path = os.path.join(HLS_OUTPUT_DIR, file)
            if os.path.isfile(file_path) and (file.endswith('.ts') or file.endswith('.m3u8')):
                os.remove(file_path)
        analytics_dir = os.path.join(HLS_OUTPUT_DIR, "analytics")
        if os.path.exists(analytics_dir):
            for file in os.listdir(analytics_dir):
                file_path = os.path.join(analytics_dir, file)
                if os.path.isfile(file_path):
                    os.remove(file_path)
        logger.info("Nettoyage des fichiers HLS et du dossier analytics effectu√©")
    except Exception as e:
        logger.error(f"Erreur lors du nettoyage des fichiers: {str(e)}")

app.mount("/hls", StaticFiles(directory=HLS_OUTPUT_DIR), name="hls")

@app.on_event("startup")
async def startup_event():
    """Actions √† ex√©cuter au d√©marrage"""
    Path(HLS_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
    Path(HLS_ANALYTICS_DIR).mkdir(parents=True, exist_ok=True)
    logger.info("Application d√©marr√©e et pr√™te √† recevoir des connexions")

if __name__ == '__main__':
    import uvicorn
    uvicorn.run(app, host='0.0.0.0', port=HTTP_PORT, log_level="info")




